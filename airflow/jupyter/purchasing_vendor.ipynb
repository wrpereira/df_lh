{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP INICIAL DO PROJETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importação das bibliotecase e pacotes necessários para a análise\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "import re\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# carregar o .env com as credenciais\n",
    "load_dotenv(\"/mnt/c/Users/wrpen/OneDrive/Desktop/df_lh/.env\")\n",
    "\n",
    "\n",
    "# detectar ambiente: como eu estou usando wsl-ubuntu, no VS Code  -  Windows, estava dando conflitos de path\n",
    "if os.name == \"nt\":  # se Windows\n",
    "    credentials_path = r\"C:\\Temp\\desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "else:  # se WSL/Linux\n",
    "    credentials_path = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "\n",
    "\n",
    "# parâmetros injetados pelo Papermill ou definidos manualmente, caso não existam no ambiente\n",
    "if 'tables_to_process' not in locals():\n",
    "    tables_to_process = [\n",
    "        \"desafioadventureworks-446600.raw_data.purchasing-vendor\"       \n",
    "    ]\n",
    "\n",
    "if 'output_dataset' not in locals():\n",
    "    output_dataset = \"desafioadventureworks-446600.raw_data_cleaned\"\n",
    "\n",
    "\n",
    "# configs do cliente BigQuery: input de project e location de acordo com dados no Bigquery\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials, project=os.getenv(\"BIGQUERY_PROJECT\"), location=\"us-central1\")\n",
    "\n",
    "\n",
    "#doc: tables_to_process: lista de tabelas que serão processadas\n",
    "#     output_dataset: nome do dataset onde os dados processados serão armazenados, neste caso, raw_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print com a tabela que vai ser processada nesse notebook\n",
    "\n",
    "print(\"Tabelas a processar:\", tables_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do dataset no Bigquery com os dados brutos (.csv) extraídos pelo Meltano \n",
    "dataset_id = 'raw_data'\n",
    "print(dataset_id)\n",
    "\n",
    "# Lista de tabelas do dataset raw_data no Bigquery\n",
    "tables = client.list_tables('raw_data')\n",
    "print(\"Tabelas disponíveis:\")\n",
    "for table in tables:\n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) e Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossário dos dados:\n",
    "\n",
    "O termo ''doc:'', situado no rodapé de algumas cells, indica algo como:\n",
    "\n",
    "- documentação: documentar decisões, análises e resultados;\n",
    "\n",
    "- abreviações de termos, como bkp, df, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inicial do df para realizar a EDA \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "#doc: df = dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os df processados\n",
    "df_processados = {}\n",
    "\n",
    "# Iteração das tabelas e armazenamento em df\n",
    "for input_table in tables_to_process:\n",
    "    print(f\"Processando tabela: {input_table}\")\n",
    "    \n",
    "    table_name = input_table.split(\".\")[-1].replace(\"-\", \"_\")  \n",
    "    \n",
    "    print(\"Lendo os dados do BigQuery...\")\n",
    "    query = f\"SELECT * FROM `{input_table}`\"\n",
    "    table_data = client.query(query).to_dataframe()\n",
    "    \n",
    "    df_processados[table_name] = table_data\n",
    "    print(f\"Tabela {table_name} processada e armazenada com sucesso.\")\n",
    "\n",
    "\n",
    "print(\"Todas as tabelas foram processadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todas as variáveis criadas dinamicamente\n",
    "for table_name in df_processados.keys():\n",
    "    print(f\"Variável criada: {table_name}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuir o df a uma variável com nome mais simples\n",
    "purchasing_vendor = df_processados['purchasing_vendor']\n",
    "\n",
    "print(f\"Colunas: {purchasing_vendor.shape[1]}\\nLinhas: {purchasing_vendor.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchasing_vendor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os valores distintos da coluna\n",
    "distinct_values = purchasing_vendor['purchasingwebserviceurl'].unique()\n",
    "\n",
    "# Contar a quantidade de valores distintos\n",
    "distinct_count = purchasing_vendor['purchasingwebserviceurl'].nunique()\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Quantidade de valores distintos: {distinct_count}\")\n",
    "print(\"Valores distintos:\")\n",
    "print(distinct_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover a coluna 'purchasingwebserviceurl'\n",
    "purchasing_vendor = purchasing_vendor.drop(columns=['purchasingwebserviceurl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar duplicadas\n",
    "duplicadas = purchasing_vendor[purchasing_vendor.duplicated(subset=['businessentityid'], keep=False)]\n",
    "\n",
    "# Verificar se existem duplicadas\n",
    "if not duplicadas.empty:\n",
    "    \n",
    "    duplicadas_ordenadas = duplicadas.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "    print(\"duplicadas ordenadas:\")\n",
    "    print(duplicadas_ordenadas)\n",
    "else:\n",
    "    print(\"Não foram encontradas duplicadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicadas* \n",
    "purchasing_vendor = purchasing_vendor.drop_duplicates(subset=['businessentityid'], keep='last')\n",
    "\n",
    "print(f\"Linhas após remover duplicadas (baseando-se na última 'modifieddate'): {len(purchasing_vendor)}\")\n",
    "\n",
    "#bkp dos dados brutos\n",
    "raw_data_bkp_2_sem_duplicadas = purchasing_vendor.copy()\n",
    "\n",
    "\n",
    "#doc: bkp = backup (cópia)\n",
    "#doc*: mantendo a última ocorrência com base em 'modifieddate', pois ela que indica a data da última modificação nos dados\n",
    "#      Importante, pois se houver erro na ingestão (duplicação), mantém os dados íntegros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar e exibir o df por 'businessentityid'\n",
    "purchasing_vendor = purchasing_vendor.sort_values(by=['businessentityid'])\n",
    "\n",
    "print(purchasing_vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar por todas as colunas do df, para verificar valores ausentes\n",
    "\n",
    "# Verificar valores ausentes na coluna\n",
    "for column in purchasing_vendor.columns:   \n",
    "    missing_rows = purchasing_vendor[purchasing_vendor[column].isnull()]\n",
    "    print(f\"Coluna '{column}': {missing_rows.shape[0]} linhas ausentes.\")\n",
    "    \n",
    "# Mostrar as primeiras linhas ausentes, se preciso for, limitar o head() para dar menos outputs ou limitar os outputs\n",
    "    if not missing_rows.empty:\n",
    "        print(f\"Exibindo as primeiras linhas com valores ausentes em '{column}':\")\n",
    "        print(missing_rows.head(), \"\\n\")\n",
    "    else:\n",
    "        print(f\"Nenhuma linha com valores ausentes em '{column}'.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos por coluna, para verificar se colunas como flags, normalmente booleanas, possuem apenas 1 ou 2 valores.\n",
    "\n",
    "valores_unicos = purchasing_vendor.nunique(dropna=False)\n",
    "\n",
    "print(\"Valores únicos incluindo NaN:\")\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar informações do df\n",
    "purchasing_vendor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliando as variáveis qualitativas*\n",
    "\n",
    "coluna_quantitativa = [\"preferredvendorstatus\", \"activeflag\",\"creditrating\"]\n",
    "for col in coluna_quantitativa:\n",
    "    counts = purchasing_vendor[col].value_counts().nlargest(10)\n",
    "    percentages = (counts / purchasing_vendor.shape[0] * 100).map(\"{:.2f}%\".format)\n",
    "    summary = pd.DataFrame({\"qtde.\": counts, \"%\": percentages})\n",
    "    print(summary)    \n",
    "\n",
    "\n",
    "#doc*: variáveis qualitativas são um tipo de variável estatística que representam características ou atributos dos dados, sem serem medidas numericamente\n",
    "#      no nosso caso, \"preferredvendorstatus\", \"activeflag, por exemplo\n",
    "\n",
    "#doc: a maioria dos fornecedores (quase 90%) é marcada como \"preferidos\", indicando que são priorizados no processo de compra.\n",
    "\n",
    "#doc: a grande maioria dos fornecedores (96%) está ativa, sugerindo que o sistema mantém apenas um pequeno número de registros inativos.\n",
    "\n",
    "#doc: a predominância de notas 1 (80.77%) indica que a empresa prioriza trabalhar com fornecedores de alta credibilidade, o que reduz riscos no processo de compras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um gráfico de barras empilhadas\n",
    "cross_tab = pd.crosstab(purchasing_vendor['preferredvendorstatus'], purchasing_vendor['activeflag'])\n",
    "cross_tab.plot(kind='bar', stacked=True, figsize=(8, 6), color=['blue', 'orange'])\n",
    "\n",
    "plt.title('Distribuição de ActiveFlag por PreferredVendorStatus', fontsize=14)\n",
    "plt.xlabel('PreferredVendorStatus', fontsize=12)\n",
    "plt.ylabel('Contagem', fontsize=12)\n",
    "plt.legend(title='ActiveFlag', fontsize=10, title_fontsize=12)\n",
    "plt.grid(False)   \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#doc: status de fornecedor preferido (preferredvendorstatus) é distribuído entre os ativos e inativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar dados e plotar\n",
    "preferred_credit = purchasing_vendor.groupby('preferredvendorstatus')['creditrating'].value_counts().unstack()\n",
    "preferred_credit.plot(kind='barh', figsize=(10, 6), color=['purple', 'green', 'red'])\n",
    "\n",
    "plt.title('Distribuição de CreditRating por PreferredVendorStatus', fontsize=14)\n",
    "plt.xlabel('Contagem', fontsize=12)\n",
    "plt.ylabel('PreferredVendorStatus', fontsize=12)\n",
    "plt.legend(title='CreditRating', fontsize=10, title_fontsize=12)\n",
    "plt.grid(False)  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#doc: a verificar como a avaliação de crédito é distribuída por status de fornecedor preferido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchasing_vendor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar o dicionário df_processados com o df ajustado\n",
    "df_processados['purchasing_vendor'] = purchasing_vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar colunas com valores textuais\n",
    "purchasing_vendor['name'] = purchasing_vendor['name'].str.strip().str.upper()\n",
    "purchasing_vendor['accountnumber'] = purchasing_vendor['accountnumber'].str.strip().str.upper()\n",
    "\n",
    "print(purchasing_vendor.head())\n",
    "\n",
    "#doc: padronizar as strings nessa etapa, contribui para a execução das demais etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que apenas tabelas únicas sejam exportadas\n",
    "unique_df_processados = {k: v for k, v in df_processados.items()}\n",
    "\n",
    "# Exportar tabelas para o BigQuery\n",
    "for table_name, df_cleaned in unique_df_processados.items():\n",
    " \n",
    "    output_table = f\"{output_dataset}.{table_name}\"\n",
    "   \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\"  \n",
    "    )\n",
    "    \n",
    "    job = client.load_table_from_dataframe(df_cleaned, output_table, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Tabela {table_name} exportada com sucesso para {output_table}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
