{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP INICIAL DO PROJETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credenciais do BigQuery: /mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#importação das bibliotecase pacotes necessários para a análise\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "import re\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Carrega o .env: onde estão as credenciais do projeto/repositório\n",
    "load_dotenv(\"/mnt/c/Users/wrpen/OneDrive/Desktop/df_lh/.env\")\n",
    "\n",
    "# Detectar ambiente: como eu estou usando wsl-ubuntu, no VS Code  -  Windows, estava dando conflitos de path\n",
    "if os.name == \"nt\":  # se Windows\n",
    "    credentials_path = r\"C:\\Temp\\desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "else:  # se WSL/Linux\n",
    "    credentials_path = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "\n",
    "# Parâmetros injetados pelo Papermill ou definidos manualmente, caso não existam no ambiente\n",
    "# Tables_to_process: lista de tabelas que serão processadas\n",
    "# Output_dataset: nome do dataset onde os dados processados serão armazenados, neste caso, raw_data_cleaned\n",
    "if 'tables_to_process' not in locals():\n",
    "    tables_to_process = [\n",
    "        \"desafioadventureworks-446600.raw_data.humanresources_employee\"       \n",
    "    ]\n",
    "\n",
    "if 'output_dataset' not in locals():\n",
    "    output_dataset = \"desafioadventureworks-446600.raw_data_cleaned\"\n",
    "\n",
    "# Configs do cliente BigQuery: input de project e location de acordo com dados no Bigquery\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials, project=os.getenv(\"BIGQUERY_PROJECT\"), location=\"us-central1\")\n",
    "\n",
    "# Print de verificação das credenciais do BigQuery e seu path\n",
    "print(\"Credenciais do BigQuery:\", os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas a processar: ['desafioadventureworks-446600.raw_data.humanresources_employee']\n"
     ]
    }
   ],
   "source": [
    "# Print com a tabela que vai ser processada nesse notebook\n",
    "\n",
    "print(\"Tabelas a processar:\", tables_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data\n"
     ]
    }
   ],
   "source": [
    "# Nome do dataset no Bigquery com os dados brutos extraídos pelo Meltano\n",
    "\n",
    "dataset_id = 'raw_data'\n",
    "print(dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas disponíveis:\n",
      "humanresources_employee\n",
      "person_address\n",
      "person_businessentity\n",
      "person_person\n",
      "production_location\n",
      "production_product\n",
      "production_productcategory\n",
      "production_productinventory\n",
      "production_productsubcategory\n",
      "sales_customer\n",
      "sales_salesorderdetail\n",
      "sales_salesorderheader\n",
      "sales_salesterritory\n",
      "sales_store\n"
     ]
    }
   ],
   "source": [
    "# Lista de tabelas do dataset raw_data no Bigquery\n",
    "\n",
    "tables = client.list_tables('raw_data')\n",
    "print(\"Tabelas disponíveis:\")\n",
    "for table in tables:\n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) e Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glossário dos dados:\n",
    "\n",
    "df = dataframe\n",
    "bkp = backup (cópia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para que o df exiba todas as colunas e todas as linhas completas, e também, \n",
    "# exiba o formato numérico com 2 dígitos após a vírgula\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando tabela: desafioadventureworks-446600.raw_data.humanresources_employee\n",
      "Lendo os dados do BigQuery...\n",
      "Transformando os dados para formato tabular...\n",
      "Tabela humanresources_employee processada e armazenada com sucesso.\n",
      "Todas as tabelas foram processadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o cliente do BigQuery Storage\n",
    "bqstorage_client = BigQueryReadClient(credentials=credentials)\n",
    "\n",
    "# Dicionário para armazenar df processados, permitindo organizar e acessar resultados intermediários ou finais por chaves - (nomes ou identificadores)\n",
    "df_processados = {}\n",
    "\n",
    "# Iteraração das tabelas e armazenamento em df\n",
    "for input_table in tables_to_process:\n",
    "    print(f\"Processando tabela: {input_table}\")\n",
    "    \n",
    "    # Nome da tabela\n",
    "    table_name = input_table.split(\".\")[-1]  # Extrai o nome da tabela\n",
    "    \n",
    "    # Etapa 1: lê os dados da tabela do BigQuery com pyarrow\n",
    "    print(\"Lendo os dados do BigQuery...\")\n",
    "    query = f\"SELECT * FROM `{input_table}`\"\n",
    "    EDA_humanresources_employee_raw = client.query(query).to_dataframe(bqstorage_client=bqstorage_client)\n",
    "\n",
    "    # Etapa 2: transforma JSON em formato tabular\n",
    "    print(\"Transformando os dados para formato tabular...\")\n",
    "\n",
    "    # Verifica se há colunas com dados em formato JSON\n",
    "    if EDA_humanresources_employee_raw.shape[1] == 1 and isinstance(EDA_humanresources_employee_raw.iloc[0, 0], str):\n",
    "        try:\n",
    "            print(\"Normalizando dados JSON...\")\n",
    "\n",
    "            # Substitui `null` por `None` e carrega o JSON: BigQuery utiliza 'null' para valores ausentes em JSON, mas o pandas utiliza None ou NaN\n",
    "            EDA_humanresources_employee = pd.json_normalize(\n",
    "                EDA_humanresources_employee_raw.iloc[:, 0].apply(lambda x: json.loads(x.replace(\"null\", \"None\")))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao normalizar JSON: {e}\")\n",
    "            EDA_humanresources_employee = EDA_humanresources_employee  # Caso falhar, mantém os dados brutos apra efeito de análise\n",
    "    else:\n",
    "        EDA_humanresources_employee = EDA_humanresources_employee_raw\n",
    "\n",
    "    # Armazenar o df limpo no dicionário para armazenar df processados\n",
    "    df_processados[table_name] = EDA_humanresources_employee\n",
    "    print(f\"Tabela {table_name} processada e armazenada com sucesso.\")\n",
    "\n",
    "# Print de validação\n",
    "print(\"Todas as tabelas foram processadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                 data                _sdc_extracted_at                 _sdc_received_at                  _sdc_batched_at _sdc_deleted_at  _sdc_sequence  _sdc_table_version\n",
      "0           {\"birthdate\":\"1969-01-29\",\"businessentityid\":1,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2009-01-14\",\"jobtitle\":\"Chief Executive Officer\",\"loginid\":\"adventure-works\\\\ken0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"295847284\",\"organizationnode\":\"/\",\"rowguid\":\"f01251e5-96a3-448d-981e-0f99d789110d\",\"salariedflag\":true,\"sickleavehours\":69,\"vacationhours\":99} 2025-01-04 15:00:48.630217+00:00 2025-01-04 12:00:49.160423+00:00 2025-01-04 12:00:49.160409+00:00             NaT  1736002849160                <NA>\n",
      "1  {\"birthdate\":\"1971-08-01\",\"businessentityid\":2,\"currentflag\":true,\"gender\":\"F\",\"hiredate\":\"2008-01-31\",\"jobtitle\":\"Vice President of Engineering\",\"loginid\":\"adventure-works\\\\terri0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"245797967\",\"organizationnode\":\"/1/\",\"rowguid\":\"45e8f437-670d-4409-93cb-f9424a40d6ee\",\"salariedflag\":true,\"sickleavehours\":20,\"vacationhours\":1} 2025-01-04 15:00:48.788338+00:00 2025-01-04 12:00:49.160635+00:00 2025-01-04 12:00:49.160409+00:00             NaT  1736002849161                <NA>\n",
      "2        {\"birthdate\":\"1974-11-12\",\"businessentityid\":3,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2007-11-11\",\"jobtitle\":\"Engineering Manager\",\"loginid\":\"adventure-works\\\\roberto0\",\"maritalstatus\":\"M\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"509647174\",\"organizationnode\":\"/1/1/\",\"rowguid\":\"9bbbfb2c-efbb-4217-9ab7-f97689328841\",\"salariedflag\":true,\"sickleavehours\":21,\"vacationhours\":2} 2025-01-04 15:00:48.788762+00:00 2025-01-04 12:00:49.160706+00:00 2025-01-04 12:00:49.160409+00:00             NaT  1736002849161                <NA>\n",
      "3       {\"birthdate\":\"1974-12-23\",\"businessentityid\":4,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2007-12-05\",\"jobtitle\":\"Senior Tool Designer\",\"loginid\":\"adventure-works\\\\rob0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"112457891\",\"organizationnode\":\"/1/1/1/\",\"rowguid\":\"59747955-87b8-443f-8ed4-f8ad3afdf3a9\",\"salariedflag\":false,\"sickleavehours\":80,\"vacationhours\":48} 2025-01-04 15:00:48.789092+00:00 2025-01-04 12:00:49.160765+00:00 2025-01-04 12:00:49.160409+00:00             NaT  1736002849161                <NA>\n",
      "4             {\"birthdate\":\"1952-09-27\",\"businessentityid\":5,\"currentflag\":true,\"gender\":\"F\",\"hiredate\":\"2008-01-06\",\"jobtitle\":\"Design Engineer\",\"loginid\":\"adventure-works\\\\gail0\",\"maritalstatus\":\"M\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"695256908\",\"organizationnode\":\"/1/1/2/\",\"rowguid\":\"ec84ae09-f9b8-4a15-b4a9-6ccbab919b08\",\"salariedflag\":true,\"sickleavehours\":22,\"vacationhours\":5} 2025-01-04 15:00:48.789274+00:00 2025-01-04 12:00:49.160840+00:00 2025-01-04 12:00:49.160409+00:00             NaT  1736002849161                <NA>\n"
     ]
    }
   ],
   "source": [
    "#Exibe as primeiras linhas do df\n",
    "print(EDA_humanresources_employee_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando os dados JSON...\n",
      "Dados normalizados com sucesso!\n",
      "Tipos atribuídos com sucesso!\n",
      "Tabela processada: desafioadventureworks-446600.raw_data.humanresources_employee\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 580 entries, 0 to 579\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   birthdate         580 non-null    object\n",
      " 1   businessentityid  580 non-null    int64 \n",
      " 2   currentflag       580 non-null    bool  \n",
      " 3   gender            580 non-null    object\n",
      " 4   hiredate          580 non-null    object\n",
      " 5   jobtitle          580 non-null    object\n",
      " 6   loginid           580 non-null    object\n",
      " 7   maritalstatus     580 non-null    object\n",
      " 8   modifieddate      574 non-null    object\n",
      " 9   nationalidnumber  580 non-null    int64 \n",
      " 10  organizationnode  580 non-null    object\n",
      " 11  rowguid           580 non-null    object\n",
      " 12  salariedflag      580 non-null    bool  \n",
      " 13  sickleavehours    580 non-null    int64 \n",
      " 14  vacationhours     580 non-null    int64 \n",
      "dtypes: bool(2), int64(4), object(9)\n",
      "memory usage: 60.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Substituir `null` por `None`, carregar o JSON e retornar `None` em caso de erro, exibindo uma mensagem com o valor problemático.\n",
    "\n",
    "def clean_and_load_json(value):\n",
    "    \"\"\"Função para corrigir e carregar JSON.\"\"\"\n",
    "    try:\n",
    "        value = value.replace(\"null\", \"None\")\n",
    "        return json.loads(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar JSON: {e}, valor problemático: {value}\")\n",
    "        return None  \n",
    "\n",
    "# Normalizar os dados JSON\n",
    "print(\"Normalizando os dados JSON...\")\n",
    "try:\n",
    "    EDA_humanresources_employee = pd.json_normalize(\n",
    "        EDA_humanresources_employee_raw.iloc[:, 0].apply(clean_and_load_json)\n",
    "    )\n",
    "    print(\"Dados normalizados com sucesso!\")\n",
    "\n",
    "    # Atribuir tipos às colunas de acordo com o banco de dados\n",
    "    EDA_humanresources_employee['businessentityid'] = EDA_humanresources_employee['businessentityid'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['nationalidnumber'] = EDA_humanresources_employee['nationalidnumber'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['loginid'] = EDA_humanresources_employee['loginid'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['jobtitle'] = EDA_humanresources_employee['jobtitle'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['birthdate'] = pd.to_datetime(EDA_humanresources_employee['birthdate'], errors='coerce').dt.date\n",
    "    EDA_humanresources_employee['maritalstatus'] = EDA_humanresources_employee['maritalstatus'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['gender'] = EDA_humanresources_employee['gender'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['hiredate'] = pd.to_datetime(EDA_humanresources_employee['hiredate'], errors='coerce').dt.date\n",
    "    EDA_humanresources_employee['salariedflag'] = EDA_humanresources_employee['salariedflag'].astype('bool')\n",
    "    EDA_humanresources_employee['vacationhours'] = EDA_humanresources_employee['vacationhours'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['sickleavehours'] = EDA_humanresources_employee['sickleavehours'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['currentflag'] = EDA_humanresources_employee['currentflag'].astype('bool')\n",
    "    EDA_humanresources_employee['rowguid'] = EDA_humanresources_employee['rowguid'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['modifieddate'] = pd.to_datetime(EDA_humanresources_employee['modifieddate'], errors='coerce').dt.date\n",
    "    EDA_humanresources_employee['organizationnode'] = EDA_humanresources_employee['organizationnode'].astype('str', errors='ignore')\n",
    "\n",
    "    print(\"Tipos atribuídos com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao normalizar os dados JSON: {e}\")\n",
    "    EDA_humanresources_employee = EDA_humanresources_employee_raw \n",
    "\n",
    "print(f\"Tabela processada: {input_table}\")\n",
    "\n",
    "print(EDA_humanresources_employee.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: 15\n",
      "Linhas: 580\n"
     ]
    }
   ],
   "source": [
    "#Verificar as dimensões do df antes de verificar as duplicatas / ausentes etc\n",
    "\n",
    "print(f\"Colunas: {EDA_humanresources_employee.shape[1]}\\nLinhas: {EDA_humanresources_employee.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicatas ordenadas:\n",
      "      birthdate  businessentityid  currentflag gender    hiredate                       jobtitle                   loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "0    1969-01-29                 1         True      M  2009-01-14        Chief Executive Officer      adventure-works\\ken0             S   2014-06-30         295847284                /  f01251e5-96a3-448d-981e-0f99d789110d          True              69             99\n",
      "290  1969-01-29                 1         True      M  2009-01-14        Chief Executive Officer      adventure-works\\ken0             S   2014-06-30         295847284                /  f01251e5-96a3-448d-981e-0f99d789110d          True              69             99\n",
      "1    1971-08-01                 2         True      F  2008-01-31  Vice President of Engineering    adventure-works\\terri0             S   2014-06-30         245797967              /1/  45e8f437-670d-4409-93cb-f9424a40d6ee          True              20              1\n",
      "291  1971-08-01                 2         True      F  2008-01-31  Vice President of Engineering    adventure-works\\terri0             S   2014-06-30         245797967              /1/  45e8f437-670d-4409-93cb-f9424a40d6ee          True              20              1\n",
      "2    1974-11-12                 3         True      M  2007-11-11            Engineering Manager  adventure-works\\roberto0             M   2014-06-30         509647174            /1/1/  9bbbfb2c-efbb-4217-9ab7-f97689328841          True              21              2\n",
      "..          ...               ...          ...    ...         ...                            ...                       ...           ...          ...               ...              ...                                   ...           ...             ...            ...\n",
      "577  1975-07-09               288         True      F  2013-05-30           Sales Representative   adventure-works\\rachel0             S   2014-06-30         954276278          /6/3/1/  b9bf7741-e0ca-4f37-acde-a4f78c6d03e9          True              37             35\n",
      "288  1968-03-17               289         True      F  2012-05-30           Sales Representative      adventure-works\\jae0             M   2014-06-30         668991357          /6/3/2/  723a5921-d8a1-4659-9bc4-13c4cf7c9c91          True              38             37\n",
      "578  1968-03-17               289         True      F  2012-05-30           Sales Representative      adventure-works\\jae0             M   2014-06-30         668991357          /6/3/2/  723a5921-d8a1-4659-9bc4-13c4cf7c9c91          True              38             37\n",
      "289  1975-09-30               290         True      M  2012-05-30           Sales Representative   adventure-works\\ranjit0             S   2014-06-30         134219713          /6/3/3/  604213f9-dd0f-43b4-bdd2-c96e93d3f4bf          True              37             34\n",
      "579  1975-09-30               290         True      M  2012-05-30           Sales Representative   adventure-works\\ranjit0             S   2014-06-30         134219713          /6/3/3/  604213f9-dd0f-43b4-bdd2-c96e93d3f4bf          True              37             34\n",
      "\n",
      "[580 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identificar duplicatas com base em 'businessentityid'\n",
    "duplicatas = EDA_humanresources_employee[\n",
    "    EDA_humanresources_employee.duplicated(subset=['businessentityid'], keep=False)\n",
    "]\n",
    "\n",
    "# Verificar se existem duplicatas\n",
    "if not duplicatas.empty:\n",
    "    # Ordenar duplicatas por 'businessentityid' e 'modifieddate'\n",
    "    duplicatas_ordenadas = duplicatas.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "    # Exibir duplicatas ordenadas\n",
    "    print(\"Duplicatas ordenadas:\")\n",
    "    print(duplicatas_ordenadas)\n",
    "else:\n",
    "    print(\"Não foram encontradas duplicatas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas após remover duplicatas (baseando-se na última 'modifieddate'): 290\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas mantendo a última ocorrência com base em 'modifieddate', pois ela que indica a data da última modificação nos dados\n",
    "# Importante, pois se houver erro na ingestão (duplicação), mantém os dados integros.\n",
    "\n",
    "EDA_humanresources_employee = EDA_humanresources_employee.drop_duplicates(subset=['businessentityid'], keep='last')\n",
    "\n",
    "print(f\"Linhas após remover duplicatas (baseando-se na última 'modifieddate'): {len(EDA_humanresources_employee)}\")\n",
    "\n",
    "#bkp dos dados brutos\n",
    "raw_data_bkp_2_sem_duplicatas = EDA_humanresources_employee.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      birthdate  businessentityid  currentflag gender    hiredate                       jobtitle                   loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "290  1969-01-29                 1         True      M  2009-01-14        Chief Executive Officer      adventure-works\\ken0             S   2014-06-30         295847284                /  f01251e5-96a3-448d-981e-0f99d789110d          True              69             99\n",
      "291  1971-08-01                 2         True      F  2008-01-31  Vice President of Engineering    adventure-works\\terri0             S   2014-06-30         245797967              /1/  45e8f437-670d-4409-93cb-f9424a40d6ee          True              20              1\n",
      "292  1974-11-12                 3         True      M  2007-11-11            Engineering Manager  adventure-works\\roberto0             M   2014-06-30         509647174            /1/1/  9bbbfb2c-efbb-4217-9ab7-f97689328841          True              21              2\n",
      "293  1974-12-23                 4         True      M  2007-12-05           Senior Tool Designer      adventure-works\\rob0             S   2014-06-30         112457891          /1/1/1/  59747955-87b8-443f-8ed4-f8ad3afdf3a9         False              80             48\n",
      "294  1952-09-27                 5         True      F  2008-01-06                Design Engineer     adventure-works\\gail0             M   2014-06-30         695256908          /1/1/2/  ec84ae09-f9b8-4a15-b4a9-6ccbab919b08          True              22              5\n",
      "..          ...               ...          ...    ...         ...                            ...                       ...           ...          ...               ...              ...                                   ...           ...             ...            ...\n",
      "575  1977-02-14               286         True      F  2013-05-30           Sales Representative     adventure-works\\lynn0             S   2014-06-30         758596752          /6/2/1/  4a9a8407-a680-4a6b-8d03-511cb58f9a8a          True              38             36\n",
      "576  1957-09-20               287         True      F  2012-04-16         European Sales Manager      adventure-works\\amy0             M   2014-06-30         982310417            /6/3/  66d66445-ee78-4676-9e66-0e22d6109a92          True              30             21\n",
      "577  1975-07-09               288         True      F  2013-05-30           Sales Representative   adventure-works\\rachel0             S   2014-06-30         954276278          /6/3/1/  b9bf7741-e0ca-4f37-acde-a4f78c6d03e9          True              37             35\n",
      "578  1968-03-17               289         True      F  2012-05-30           Sales Representative      adventure-works\\jae0             M   2014-06-30         668991357          /6/3/2/  723a5921-d8a1-4659-9bc4-13c4cf7c9c91          True              38             37\n",
      "579  1975-09-30               290         True      M  2012-05-30           Sales Representative   adventure-works\\ranjit0             S   2014-06-30         134219713          /6/3/3/  604213f9-dd0f-43b4-bdd2-c96e93d3f4bf          True              37             34\n",
      "\n",
      "[290 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ordenar e exibir o df por 'businessentityid' e 'modifieddate'\n",
    "EDA_humanresources_employee = EDA_humanresources_employee.sort_values(by=['businessentityid'])\n",
    "\n",
    "print(EDA_humanresources_employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 290 entries, 290 to 579\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   birthdate         290 non-null    object\n",
      " 1   businessentityid  290 non-null    int64 \n",
      " 2   currentflag       290 non-null    bool  \n",
      " 3   gender            290 non-null    object\n",
      " 4   hiredate          290 non-null    object\n",
      " 5   jobtitle          290 non-null    object\n",
      " 6   loginid           290 non-null    object\n",
      " 7   maritalstatus     290 non-null    object\n",
      " 8   modifieddate      287 non-null    object\n",
      " 9   nationalidnumber  290 non-null    int64 \n",
      " 10  organizationnode  290 non-null    object\n",
      " 11  rowguid           290 non-null    object\n",
      " 12  salariedflag      290 non-null    bool  \n",
      " 13  sickleavehours    290 non-null    int64 \n",
      " 14  vacationhours     290 non-null    int64 \n",
      "dtypes: bool(2), int64(4), object(9)\n",
      "memory usage: 32.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Verificar se as colunas de datas têm valores nulos (NaN em pandas), pois não pode object, para afacilitar manipulação dos dados\n",
    "print(EDA_humanresources_employee.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna 'birthdate': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'birthdate'.\n",
      "\n",
      "Coluna 'businessentityid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'businessentityid'.\n",
      "\n",
      "Coluna 'currentflag': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'currentflag'.\n",
      "\n",
      "Coluna 'gender': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'gender'.\n",
      "\n",
      "Coluna 'hiredate': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'hiredate'.\n",
      "\n",
      "Coluna 'jobtitle': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'jobtitle'.\n",
      "\n",
      "Coluna 'loginid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'loginid'.\n",
      "\n",
      "Coluna 'maritalstatus': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'maritalstatus'.\n",
      "\n",
      "Coluna 'modifieddate': 3 linhas ausentes.\n",
      "Exibindo as primeiras linhas com valores ausentes em 'modifieddate':\n",
      "      birthdate  businessentityid  currentflag gender    hiredate                    jobtitle                  loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "315  1982-11-03                26         True      M  2008-12-01  Production Control Manager   adventure-works\\peter0             M          NaT         277173473            /3/1/  69d5d162-e817-45e7-9dec-5d9b8310e7b1          True              41             43\n",
      "500  1977-10-26               211         True      M  2009-02-28   Quality Assurance Manager   adventure-works\\hazem0             S          NaT         398223854            /3/2/  05c84608-f445-4f9d-bb5c-0828c309c29d          True              60             80\n",
      "511  1968-09-17               222         True      M  2008-12-12            Master Scheduler  adventure-works\\ascott0             S          NaT         685233686            /3/3/  13909262-4136-492f-bca3-0b0e3773b03e         False              42             44 \n",
      "\n",
      "Coluna 'nationalidnumber': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'nationalidnumber'.\n",
      "\n",
      "Coluna 'organizationnode': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'organizationnode'.\n",
      "\n",
      "Coluna 'rowguid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'rowguid'.\n",
      "\n",
      "Coluna 'salariedflag': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'salariedflag'.\n",
      "\n",
      "Coluna 'sickleavehours': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'sickleavehours'.\n",
      "\n",
      "Coluna 'vacationhours': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'vacationhours'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar por todas as colunas do df, para verificar valores ausentes\n",
    "\n",
    " # Verificar valores ausentes na coluna\n",
    "for column in EDA_humanresources_employee.columns:   \n",
    "    missing_rows = EDA_humanresources_employee[EDA_humanresources_employee[column].isnull()]\n",
    "    print(f\"Coluna '{column}': {missing_rows.shape[0]} linhas ausentes.\")\n",
    "    \n",
    "# Mostrar as primeiras linhas ausentes, se preciso for, limitar o head() para dar menos outputs ou limitar os outputs\n",
    "    if not missing_rows.empty:\n",
    "        print(f\"Exibindo as primeiras linhas com valores ausentes em '{column}':\")\n",
    "        print(missing_rows.head(), \"\\n\")\n",
    "    else:\n",
    "        print(f\"Nenhuma linha com valores ausentes em '{column}'.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas onde 'modifieddate' foi ajustado para 'hiredate':\n",
      "      birthdate  businessentityid  currentflag gender    hiredate                    jobtitle                  loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "315  1982-11-03                26         True      M  2008-12-01  Production Control Manager   adventure-works\\peter0             M   2008-12-01         277173473            /3/1/  69d5d162-e817-45e7-9dec-5d9b8310e7b1          True              41             43\n",
      "500  1977-10-26               211         True      M  2009-02-28   Quality Assurance Manager   adventure-works\\hazem0             S   2009-02-28         398223854            /3/2/  05c84608-f445-4f9d-bb5c-0828c309c29d          True              60             80\n",
      "511  1968-09-17               222         True      M  2008-12-12            Master Scheduler  adventure-works\\ascott0             S   2008-12-12         685233686            /3/3/  13909262-4136-492f-bca3-0b0e3773b03e         False              42             44\n"
     ]
    }
   ],
   "source": [
    "# Preencher 'modifieddate' ausente ou igual a 'hiredate', por ser a última data de modificação no sistema.\n",
    "EDA_humanresources_employee.loc[EDA_humanresources_employee['modifieddate'].isnull() | (EDA_humanresources_employee['modifieddate'] == pd.Timestamp('1900-01-01')), 'modifieddate'] = EDA_humanresources_employee['hiredate']\n",
    "\n",
    "# Exibir as linhas ajustadas\n",
    "print(\"Linhas onde 'modifieddate' foi ajustado para 'hiredate':\")\n",
    "print(EDA_humanresources_employee.loc[EDA_humanresources_employee['modifieddate'] == EDA_humanresources_employee['hiredate']])\n",
    "\n",
    "# bkp do df\n",
    "ajustes_modifieddate = EDA_humanresources_employee.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos incluindo NaN:\n",
      "birthdate           275\n",
      "businessentityid    290\n",
      "currentflag           1\n",
      "gender                2\n",
      "hiredate            164\n",
      "jobtitle             67\n",
      "loginid             290\n",
      "maritalstatus         2\n",
      "modifieddate          4\n",
      "nationalidnumber    290\n",
      "organizationnode    290\n",
      "rowguid             290\n",
      "salariedflag          2\n",
      "sickleavehours       51\n",
      "vacationhours       100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos por coluna, para verificar se colunas como flags, normalmente booleanas, possuem apenas 1 ou 2 valores.\n",
    "\n",
    "valores_unicos = EDA_humanresources_employee.nunique(dropna=False)\n",
    "\n",
    "print(\"Valores únicos incluindo NaN:\")\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropar colunas vazias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar textos em title (ex: Production Supervisor) ou upper (ex:M)\n",
    "EDA_humanresources_employee['jobtitle'] = EDA_humanresources_employee['jobtitle'].str.strip().str.title()\n",
    "EDA_humanresources_employee['gender'] = EDA_humanresources_employee['gender'].str.strip().str.upper()\n",
    "EDA_humanresources_employee['maritalstatus'] = EDA_humanresources_employee['maritalstatus'].str.strip().str.upper()\n",
    "\n",
    "# Criar um backup do df tratado\n",
    "EDA_humanresources_employee_bkp_v2 = EDA_humanresources_employee.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores inválidos em 'nationalidnumber':\n",
      "303    42487730\n",
      "304    56920285\n",
      "305    24756624\n",
      "308    52541318\n",
      "311    95958330\n",
      "313    72636981\n",
      "317    14417807\n",
      "327     6298838\n",
      "335    66073987\n",
      "336    33237992\n",
      "342     9659517\n",
      "346    10708100\n",
      "350    92096924\n",
      "354     8066363\n",
      "356    63179277\n",
      "359    36151748\n",
      "371    58791499\n",
      "374     1662732\n",
      "376     7201901\n",
      "378    90888098\n",
      "379    82638150\n",
      "402    54759846\n",
      "421     1300049\n",
      "423    45615666\n",
      "426    63761469\n",
      "427    25011600\n",
      "432    56772045\n",
      "443    97728960\n",
      "453    65848458\n",
      "455    60114406\n",
      "462    87268837\n",
      "487    19312190\n",
      "499    20244403\n",
      "519    28414965\n",
      "530       30845\n",
      "532    60517918\n",
      "548    20269531\n",
      "556    58317344\n",
      "569    61161660\n",
      "573    90836195\n",
      "Name: nationalidnumber, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Definir regex para validar números (exemplo: apenas dígitos, 9 caracteres)\n",
    "# Acrescentei para ver se tinha um padrão, mas não tem.\n",
    "regex = r'^\\d{9}$'\n",
    "\n",
    "# Verificar valores inválidos de acordo com a regra do regex anterior\n",
    "invalid_nationalid = EDA_humanresources_employee[~EDA_humanresources_employee['nationalidnumber'].astype(str).str.match(regex)]\n",
    "print(f\"Valores inválidos em 'nationalidnumber':\\n{invalid_nationalid['nationalidnumber']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'currentflag': [ True]\n",
      "Valores únicos em 'salariedflag': [ True False]\n"
     ]
    }
   ],
   "source": [
    "# Listar colunas binárias esperadas\n",
    "binary_columns = ['currentflag', 'salariedflag']\n",
    "\n",
    "# Verificar valores únicos em colunas binárias\n",
    "for col in binary_columns:\n",
    "    unique_values = EDA_humanresources_employee[col].unique()\n",
    "    print(f\"Valores únicos em '{col}': {unique_values}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de 'currentflag':\n",
      "currentflag\n",
      "True    290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição de 'salariedflag':\n",
      "salariedflag\n",
      "False    238\n",
      "True      52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores em 'currentflag' e 'salariedflag'\n",
    "print(\"Distribuição de 'currentflag':\")\n",
    "print(EDA_humanresources_employee['currentflag'].value_counts())\n",
    "\n",
    "print(\"\\nDistribuição de 'salariedflag':\")\n",
    "print(EDA_humanresources_employee['salariedflag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcionários ativos errados: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n",
      "Contratações futuras: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n",
      "Modifieddate antes de hiredate: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Verificar se há funcionários ativos com `false`, já que `false` indica demitido/desligado, portanto, não deveriam ser considerados ativos\n",
    "print(\"Funcionários ativos errados:\", EDA_humanresources_employee[EDA_humanresources_employee['currentflag'] != True])\n",
    "\n",
    "# Validar datas\n",
    "print(\"Contratações futuras:\", EDA_humanresources_employee[pd.to_datetime(EDA_humanresources_employee['hiredate'], errors='coerce') > pd.Timestamp.now()])\n",
    "print(\"Modifieddate antes de hiredate:\", EDA_humanresources_employee[pd.to_datetime(EDA_humanresources_employee['modifieddate'], errors='coerce') < pd.to_datetime(EDA_humanresources_employee['hiredate'], errors='coerce')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 290 entries, 290 to 579\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   birthdate         290 non-null    object\n",
      " 1   businessentityid  290 non-null    int64 \n",
      " 2   currentflag       290 non-null    bool  \n",
      " 3   gender            290 non-null    object\n",
      " 4   hiredate          290 non-null    object\n",
      " 5   jobtitle          290 non-null    object\n",
      " 6   loginid           290 non-null    object\n",
      " 7   maritalstatus     290 non-null    object\n",
      " 8   modifieddate      290 non-null    object\n",
      " 9   nationalidnumber  290 non-null    int64 \n",
      " 10  organizationnode  290 non-null    object\n",
      " 11  rowguid           290 non-null    object\n",
      " 12  salariedflag      290 non-null    bool  \n",
      " 13  sickleavehours    290 non-null    int64 \n",
      " 14  vacationhours     290 non-null    int64 \n",
      "dtypes: bool(2), int64(4), object(9)\n",
      "memory usage: 40.4+ KB\n"
     ]
    }
   ],
   "source": [
    "EDA_humanresources_employee.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar o dicionário df_processados com o df ajustado\n",
    "df_processados['humanresources_employee'] = EDA_humanresources_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sickleavehours  vacationhours\n",
      "count          290.00         290.00\n",
      "mean            45.31          50.61\n",
      "std             14.54          28.79\n",
      "min             20.00           0.00\n",
      "25%             33.00          26.25\n",
      "50%             46.00          51.00\n",
      "75%             58.00          75.00\n",
      "max             80.00          99.00\n",
      "\n",
      "Coluna: sickleavehours\n",
      "Limite inferior: -4.5, Limite superior: 95.5\n",
      "Outliers detectados (0):\n",
      "Empty DataFrame\n",
      "Columns: [sickleavehours]\n",
      "Index: []\n",
      "\n",
      "Coluna: vacationhours\n",
      "Limite inferior: -46.875, Limite superior: 148.125\n",
      "Outliers detectados (0):\n",
      "Empty DataFrame\n",
      "Columns: [vacationhours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Estatística descritiva para verificar se ainda há o que ser feito antes de exportar os dados ao BigQuery\n",
    "\n",
    "# Identificar colunas numéricas para análise de outliers\n",
    "numeric_columns = ['sickleavehours', 'vacationhours']\n",
    "\n",
    "# Exibir estatísticas descritivas para entender a variação e centralidade dos dados.\n",
    "print(EDA_humanresources_employee[numeric_columns].describe())\n",
    "\n",
    "# Calcular limites para outliers (IQR - Intervalo Interquartil), para verificar valores atípicos (remoção, capping, imputação)\n",
    "    # Remoção: excluir as linhas\n",
    "    # Capping: substituir os valores fora dos limites pelo valor do limite inferior ou superior\n",
    "    # Imputação: substituir os valores outliers por medidas centrais, como a média ou mediana, se isso fizer sentido\n",
    "\n",
    "for col in numeric_columns:\n",
    "    q1 = EDA_humanresources_employee[col].quantile(0.25)\n",
    "    q3 = EDA_humanresources_employee[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Exibir os limites\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Limite inferior: {lower_bound}, Limite superior: {upper_bound}\")\n",
    "    \n",
    "    # Filtrar outliers\n",
    "    outliers = EDA_humanresources_employee[(EDA_humanresources_employee[col] < lower_bound) | (EDA_humanresources_employee[col] > upper_bound)]\n",
    "    print(f\"Outliers detectados ({len(outliers)}):\")\n",
    "    print(outliers[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela humanresources_employee exportada com sucesso para desafioadventureworks-446600.raw_data_cleaned.humanresources_employee.\n"
     ]
    }
   ],
   "source": [
    "# Garantir que apenas tabelas únicas sejam exportadas\n",
    "unique_df_processados = {k: v for k, v in df_processados.items()}\n",
    "\n",
    "# Exportar tabelas para o BigQuery\n",
    "for table_name, df_cleaned in unique_df_processados.items():\n",
    "    # Remover o prefixo 'stg_' para exibição e exportação\n",
    "    clean_table_name = table_name.replace(\"stg_\", \"\")\n",
    "\n",
    "    # Nome da tabela no BigQuery sem 'stg_'\n",
    "    output_table = f\"{output_dataset}.{clean_table_name}\"\n",
    "\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"birthdate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"businessentityid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"currentflag\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"gender\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"hiredate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"jobtitle\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"loginid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"maritalstatus\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"modifieddate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"nationalidnumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"organizationnode\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"rowguid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"salariedflag\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"sickleavehours\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"vacationhours\", \"INTEGER\"),\n",
    "    ]\n",
    "    filtered_schema = [field for field in schema if field.name in df_cleaned.columns]\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=0,\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "        schema=filtered_schema,\n",
    "    )\n",
    "    job = client.load_table_from_dataframe(df_cleaned, output_table, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Tabela {clean_table_name} exportada com sucesso para {output_table}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
