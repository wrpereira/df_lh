{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP INICIAL DO PROJETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importação das bibliotecase e pacotes necessários para a análise\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Carrega o .env: onde estão as credenciais do projeto/repositório\n",
    "load_dotenv(\"/mnt/c/Users/wrpen/OneDrive/Desktop/df_lh/.env\")\n",
    "\n",
    "# Detectar ambiente: como eu estou usando wsl-ubuntu, no VS Code  -  Windows, estava dando conflitos de path\n",
    "if os.name == \"nt\":  # se Windows\n",
    "    credentials_path = r\"C:\\Temp\\desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "else:  # se WSL/Linux\n",
    "    credentials_path = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "\n",
    "# Parâmetros injetados pelo Papermill ou definidos manualmente, caso não existam no ambiente\n",
    "# Tables_to_process: lista de tabelas que serão processadas\n",
    "# Output_dataset: nome do dataset onde os dados processados serão armazenados, neste caso, raw_data_cleaned\n",
    "if 'tables_to_process' not in locals():\n",
    "    tables_to_process = [\n",
    "        \"desafioadventureworks-446600.raw_data.humanresources-employee\"       \n",
    "    ]\n",
    "\n",
    "if 'output_dataset' not in locals():\n",
    "    output_dataset = \"desafioadventureworks-446600.raw_data_cleaned\"\n",
    "\n",
    "# Configs do cliente BigQuery: input de project e location de acordo com dados no Bigquery\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials, project=os.getenv(\"BIGQUERY_PROJECT\"), location=\"us-central1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print com a tabela que vai ser processada nesse notebook\n",
    "\n",
    "print(\"Tabelas a processar:\", tables_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do dataset no Bigquery com os dados brutos (.csv) extraídos pelo Meltano \n",
    "dataset_id = 'raw_data'\n",
    "print(dataset_id)\n",
    "\n",
    "# Lista de tabelas do dataset raw_data no Bigquery\n",
    "tables = client.list_tables('raw_data')\n",
    "print(\"Tabelas disponíveis:\")\n",
    "for table in tables:\n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) e Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossário dos dados:\n",
    "\n",
    "O termo ''doc:'', situado no rodapé de algumas cells, indica algo como:\n",
    "\n",
    "- documentação: documentar decisões, análises e resultados;\n",
    "\n",
    "- abreviações de termos, como bkp, df, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para que o df exiba todas as colunas e todas as linhas completas, e também, exiba o formato numérico com 2 dígitos após a vírgula\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "#doc: df = dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os df processados\n",
    "df_processados = {}\n",
    "\n",
    "# Iteração das tabelas e armazenamento em df\n",
    "for input_table in tables_to_process:\n",
    "    print(f\"Processando tabela: {input_table}\")\n",
    "    \n",
    "    # Nome da tabela com substituição de '-' por '_'\n",
    "    table_name = input_table.split(\".\")[-1].replace(\"-\", \"_\")  \n",
    "    \n",
    "    # Ler os dados da tabela do BigQuery para um df\n",
    "    print(\"Lendo os dados do BigQuery...\")\n",
    "    query = f\"SELECT * FROM `{input_table}`\"\n",
    "    table_data = client.query(query).to_dataframe()\n",
    "    \n",
    "    # Armazenar o df no dicionário\n",
    "    df_processados[table_name] = table_data\n",
    "    print(f\"Tabela {table_name} processada e armazenada com sucesso.\")\n",
    "\n",
    "# Print de validação\n",
    "print(\"Todas as tabelas foram processadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todas as variáveis criadas dinamicamente\n",
    "for table_name in df_processados.keys():\n",
    "    print(f\"Variável criada: {table_name}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuir o df a uma variável com nome mais simples\n",
    "humanresources_employee = df_processados['humanresources_employee']\n",
    "\n",
    "print(f\"Colunas: {humanresources_employee.shape[1]}\\nLinhas: {humanresources_employee.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar duplicadas com base em 'businessentityid'\n",
    "duplicadas = humanresources_employee[\n",
    "    humanresources_employee.duplicated(subset=['businessentityid'], keep=False)\n",
    "]\n",
    "\n",
    "# Verificar se existem duplicadas\n",
    "if not duplicadas.empty:\n",
    "    # Ordenar duplicadas por 'businessentityid' e 'modifieddate'\n",
    "    duplicadas_ordenadas = duplicadas.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "    # Exibir duplicadas ordenadas\n",
    "    print(\"duplicadas ordenadas:\")\n",
    "    print(duplicadas_ordenadas)\n",
    "else:\n",
    "    print(\"Não foram encontradas duplicadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicadas mantendo a última ocorrência com base em 'modifieddate', pois ela que indica a data da última modificação nos dados\n",
    "# Importante, pois se houver erro na ingestão (duplicação), mantém os dados integros.\n",
    "\n",
    "humanresources_employee = humanresources_employee.drop_duplicates(subset=['businessentityid'], keep='last')\n",
    "\n",
    "print(f\"Linhas após remover duplicadas (baseando-se na última 'modifieddate'): {len(humanresources_employee)}\")\n",
    "\n",
    "#bkp dos dados brutos\n",
    "raw_data_bkp_2_sem_duplicadas = humanresources_employee.copy()\n",
    "\n",
    "\n",
    "#doc: bkp = backup (cópia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar e exibir o df por 'businessentityid'\n",
    "humanresources_employee = humanresources_employee.sort_values(by=['businessentityid'])\n",
    "\n",
    "print(humanresources_employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar por todas as colunas do df, para verificar valores ausentes\n",
    "\n",
    "# Verificar valores ausentes na coluna\n",
    "for column in humanresources_employee.columns:   \n",
    "    missing_rows = humanresources_employee[humanresources_employee[column].isnull()]\n",
    "    print(f\"Coluna '{column}': {missing_rows.shape[0]} linhas ausentes.\")\n",
    "    \n",
    "# Mostrar as primeiras linhas ausentes, se preciso for, limitar o head() para dar menos outputs ou limitar os outputs\n",
    "    if not missing_rows.empty:\n",
    "        print(f\"Exibindo as primeiras linhas com valores ausentes em '{column}':\")\n",
    "        print(missing_rows.head(), \"\\n\")\n",
    "    else:\n",
    "        print(f\"Nenhuma linha com valores ausentes em '{column}'.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos por coluna, para verificar se colunas como flags, normalmente booleanas, possuem apenas 1 ou 2 valores.\n",
    "\n",
    "valores_unicos = humanresources_employee.nunique(dropna=False)\n",
    "\n",
    "print(\"Valores únicos incluindo NaN:\")\n",
    "print(valores_unicos)\n",
    "\n",
    "#doc: currentflag possue somente 1 valor, o que indica que pode ser somente valores True ou False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar colunas binárias esperadas e verificar valores únicos e suas distribuições\n",
    "coluna_binaria = ['currentflag', 'salariedflag']\n",
    "\n",
    "for col in coluna_binaria:\n",
    "    unique_values = humanresources_employee[col].unique()\n",
    "    print(f\"Valores únicos em '{col}': {unique_values}\")\n",
    "    print(f\"Distribuição de '{col}':\")\n",
    "    print(humanresources_employee[col].value_counts())\n",
    "    print()\n",
    "\n",
    "\n",
    "#doc: garantir que colunas binárias contenham apenas valores esperados, no caso True ou False e identificar anomalias verificando os valores únicos em cada coluna; valores fora do padrão binário, facilitando a validação e correção\n",
    "#doc: currentflag só tem True, isso indica que a coluna é constante e não agrega informações úteis para a análise, pois não há variabilidade nos dados, ao contrario de salariedflag, que é uma coluna válida para análise, já que possui variabilidade e pode ser utilizada para segmentar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se há funcionários ativos com `false`*\n",
    "print(\"Funcionários ativos errados:\", humanresources_employee[humanresources_employee['currentflag'] != True])\n",
    "\n",
    "# Validar datas\n",
    "# Converter 'hiredate' e 'modifieddate' para datetime sem timezone\n",
    "hiredate = pd.to_datetime(humanresources_employee['hiredate'], errors='coerce').dt.tz_localize(None)\n",
    "modifieddate = pd.to_datetime(humanresources_employee['modifieddate'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Contratações futuras**\n",
    "print(\"Contratações futuras:\", humanresources_employee[hiredate > pd.Timestamp.now()])\n",
    "\n",
    "# Modifieddate antes de hiredate***\n",
    "print(\"Modifieddate antes de hiredate:\", humanresources_employee[modifieddate < hiredate])\n",
    "\n",
    "\n",
    "#doc*: funcionários desligados / demitidos (False) não devem ser tratados como ativos no sistema, evitando inconsistências\n",
    "#doc**:datas futuras indicam erros nos registros, pois contratações devem ocorrer em datas passadas\n",
    "#doc***: um registro não pode ser modificado antes da contratação, pois seria um erro lógico nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar informações do df\n",
    "humanresources_employee.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliando as variáveis qualitativas*\n",
    "\n",
    "coluna_quantitativa = [\"jobtitle\", \"maritalstatus\", \"gender\"]\n",
    "for col in coluna_quantitativa:\n",
    "    counts = humanresources_employee[col].value_counts().nlargest(10)\n",
    "    percentages = (counts / humanresources_employee.shape[0] * 100).map(\"{:.2f}%\".format)\n",
    "    summary = pd.DataFrame({\"qtde.\": counts, \"%\": percentages})\n",
    "    print(summary)    \n",
    "\n",
    "\n",
    "#doc*: variáveis qualitativas são um tipo de variável estatística que representam características ou atributos dos dados, sem serem medidas numericamente\n",
    "#      no nosso caso, jobtitle, maritalstatus, gender, por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis quantitativas*: estatísticas descritivas para verificar se ainda há o que ser feito antes de exportar os dados ao BigQuery\n",
    "\n",
    "# Identificar colunas numéricas para análise de outliers\n",
    "numeric_columns = ['sickleavehours', 'vacationhours']\n",
    "\n",
    "# Estatísticas Descritivas das colunas numéricas*\n",
    "print(humanresources_employee[numeric_columns].describe())\n",
    "\n",
    "# Cálculo de limites para outliers (IQR)**\n",
    "for col in numeric_columns:\n",
    "    q1 = humanresources_employee[col].quantile(0.25)\n",
    "    q3 = humanresources_employee[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Exibir os limites\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Limite inferior: {lower_bound}, Limite superior: {upper_bound}\")\n",
    "    \n",
    "    # Detecção e Análise de Outliers***\n",
    "    outliers = humanresources_employee[(humanresources_employee[col] < lower_bound) | (humanresources_employee[col] > upper_bound)]\n",
    "    print(f\"Outliers detectados ({len(outliers)}):\")\n",
    "    print(outliers[[col]])\n",
    "\n",
    "\n",
    "#doc*: variáveis quantitativas são um tipo de dado que pode ser representado por números e medidas objetivas, no nosso caso, vacationhours, sickleavehours, por exemplo\n",
    "#doc*: realizar estatísticas descritivas para entender a centralidade e variação dos dados (valores médios, mínimos, máximos, etc.)\n",
    "#doc**: calcular limites para identificar outliers (valores extremos que podem indicar erros ou casos excepcionais nos dados)\n",
    "#doc***: verificar a existência de outliers para decidir ações como remoção, substituição ou tratamento, garantindo qualidade dos dados\n",
    "#doc****: as colunas analisadas não apresentam outliers, pois os dados estão dentro dos limites esperados, sugerindo que não há necessidade de tratamento adicional para valores extremos. Isso indica boa qualidade dos dados para essas variáveis e que elas estão prontas para serem exportadas ou utilizadas em análises e modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o estilo do gráfico para fundo escuro\n",
    "sns.set(style='darkgrid', rc={\"axes.facecolor\": \"black\", \"figure.facecolor\": \"black\"})\n",
    "\n",
    "# Gráfico de barras para maritalstatus x gender\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(\n",
    "    x='maritalstatus', hue='gender', data=humanresources_employee,\n",
    "    palette={\"M\": \"blue\", \"F\": \"pink\"}  \n",
    ")\n",
    "plt.title('Estado Civil vs Gênero', color='white')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"Estado Civil\", color='white')\n",
    "\n",
    "# Cor dos rótulos\n",
    "ax.tick_params(axis='x', colors='white')\n",
    "ax.tick_params(axis='y', colors='white')\n",
    "\n",
    "# Remover os números do eixo Y\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Valores no topo de cada barra\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d', label_type='edge', color='white', fontsize=10)\n",
    "\n",
    "# Grade\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5, color='gray')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#doc: maritalstatus: M = married | casado ; S = single | Solteiro\n",
    "#     gender: M = male | homem ; F = female | mulher \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o estilo do gráfico\n",
    "sns.set(style='darkgrid', rc={\"axes.facecolor\": \"black\", \"figure.facecolor\": \"black\"})\n",
    "\n",
    "# Calcular os quartis\n",
    "quartiles = humanresources_employee.groupby('gender')['vacationhours'].quantile([0.25, 0.50, 0.75]).unstack()\n",
    "\n",
    "# Gráfico de boxplot para gender x vacationhours\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(\n",
    "    x='gender', y='vacationhours', data=humanresources_employee, showmeans=True,\n",
    "    meanprops={\"marker\": \"o\", \"markerfacecolor\": \"white\", \"markeredgecolor\": \"black\", \"markersize\": 5},\n",
    "    boxprops={\"color\": \"green\"}, whiskerprops={\"color\": \"green\"}, capprops={\"color\": \"green\"},\n",
    "    medianprops={\"color\": \"red\"}, flierprops={\"markerfacecolor\": \"blue\", \"markersize\": 5}\n",
    ")\n",
    "plt.title('Gênero vs Férias Acumuladas (horas)', color='white')\n",
    "plt.ylabel(\"Férias Acumuladas (horas)\", color='white')\n",
    "plt.xlabel(\"Gênero\", color='white')\n",
    "\n",
    "# Cor dos rótulos\n",
    "ax.tick_params(axis='x', colors='white')\n",
    "ax.tick_params(axis='y', colors='white')\n",
    "\n",
    "# Quartis ao lado das caixas\n",
    "for gender, values in quartiles.iterrows():\n",
    "    x_pos = list(humanresources_employee['gender'].unique()).index(gender)  # Posição x da barra\n",
    "    offset = 0.4\n",
    "\n",
    "    for i, quartile in enumerate(values):\n",
    "        y_pos = quartile\n",
    "        ax.text(x=x_pos + offset, y=y_pos, s=f\"{quartile:.1f}\", ha='left', va='center', fontsize=10, color='white')\n",
    "\n",
    "# Grade\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5, color='gray')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#doc: vacationhours: férias acumuladas por funcionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular os quartis\n",
    "quartiles = humanresources_employee.groupby('gender')['sickleavehours'].quantile([0.25, 0.50, 0.75]).unstack()\n",
    "\n",
    "# Gráfico de boxplot para gender x sickleavehours\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(\n",
    "    x='gender', y='sickleavehours', data=humanresources_employee,\n",
    "    boxprops={\"color\": \"green\"}, whiskerprops={\"color\": \"green\"}, capprops={\"color\": \"green\"},\n",
    "    medianprops={\"color\": \"red\"}, flierprops={\"markerfacecolor\": \"blue\", \"markersize\": 5}\n",
    ")\n",
    "plt.title('Gênero vs Licença Médica (horas)', color='white')\n",
    "plt.ylabel(\"Licença Médica (horas)\", color='white')\n",
    "plt.xlabel(\"Gênero\", color='white')\n",
    "\n",
    "# Cor dos rótulos\n",
    "ax.tick_params(axis='x', colors='white')\n",
    "ax.tick_params(axis='y', colors='white')\n",
    "\n",
    "# Quartis ao lado das caixas\n",
    "for gender, values in quartiles.iterrows():\n",
    "    x_pos = list(humanresources_employee['gender'].unique()).index(gender)  # Posição x da barra\n",
    "    offset = 0.4\n",
    "\n",
    "    for i, quartile in enumerate(values):\n",
    "        y_pos = quartile\n",
    "        ax.text(x=x_pos + offset, y=y_pos, s=f\"{quartile:.1f}\", ha='left', va='center', fontsize=10, color='white')\n",
    "\n",
    "# Grade\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5, color='gray')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#doc: sickleavehours: horas de licença médica por funcionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar o dicionário df_processados com o df ajustado\n",
    "df_processados['humanresources_employee'] = humanresources_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar colunas com valores textuais\n",
    "humanresources_employee['jobtitle'] = humanresources_employee['jobtitle'].str.strip().str.upper()\n",
    "humanresources_employee['gender'] = humanresources_employee['gender'].str.strip().str.upper()\n",
    "humanresources_employee['maritalstatus'] = humanresources_employee['maritalstatus'].str.strip().str.upper()\n",
    "humanresources_employee['loginid'] = humanresources_employee['loginid'].str.strip().str.upper()\n",
    "humanresources_employee['rowguid'] = humanresources_employee['rowguid'].str.strip().str.upper()\n",
    "\n",
    "print(humanresources_employee.head())\n",
    "\n",
    "#doc: padronizar as strings nessa etapa, contribui para a execução das demais etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Garantir que apenas tabelas únicas sejam exportadas\n",
    "unique_df_processados = {k: v for k, v in df_processados.items()}\n",
    "\n",
    "# Exportar tabelas para o BigQuery\n",
    "for table_name, df_cleaned in unique_df_processados.items():\n",
    "    # Nome da tabela no BigQuery\n",
    "    output_table = f\"{output_dataset}.{table_name}\"\n",
    "\n",
    "    # Configurar job de exportação\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\"  \n",
    "    )\n",
    "    \n",
    "    # Exportar DataFrame para o BigQuery\n",
    "    job = client.load_table_from_dataframe(df_cleaned, output_table, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Tabela {table_name} exportada com sucesso para {output_table}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
