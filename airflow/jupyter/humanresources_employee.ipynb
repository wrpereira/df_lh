{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import das bibliotecas e adequando colunas, linhas e formato de números\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "\n",
    "\n",
    "# Configurar Pandas para exibir todas as colunas e todas as linhas completas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o cliente do BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Nome do dataset e tabela\n",
    "dataset_id = 'raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar tabelas no dataset\n",
    "tables = client.list_tables('raw_data')\n",
    "print(\"Tabelas disponíveis:\")\n",
    "for table in tables:\n",
    "    print(table.table_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM `raw_data.humanresources_employee`\"\n",
    "data = client.query(query).result().to_dataframe()\n",
    "\n",
    "# Expandir a coluna JSON\n",
    "raw_data = pd.json_normalize(data['data'])\n",
    "\n",
    "# Exibir os dados expandidos\n",
    "print(raw_data.sample(n=50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores nulos/em branco nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores nulos\n",
    "\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total valores unicos de cada variável\n",
    "\n",
    "valores_unicos = []\n",
    "\n",
    "for i in raw_data.columns[0:15].tolist():\n",
    "    print(i, ':', len(raw_data[i].astype(str).value_counts()))\n",
    "    valores_unicos.append(len(raw_data[i].astype(str).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar duplicatas com base em 'businessentityid'\n",
    "duplicatas = raw_data[raw_data.duplicated(subset=['businessentityid'], keep=False)]\n",
    "\n",
    "# Verificar se existem duplicatas\n",
    "if not duplicatas.empty:\n",
    "    # Ordenar duplicatas por 'businessentityid' e 'modifieddate'\n",
    "    duplicatas_ordenadas = duplicatas.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "    \n",
    "    # Exibir duplicatas ordenadas\n",
    "    print(\"Duplicatas ordenadas:\")\n",
    "    print(duplicatas_ordenadas)\n",
    "else:\n",
    "    print(\"Não foram encontradas duplicatas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicatas_ordenadas.drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados_businessentityid = raw_data[raw_data.duplicated(subset=['businessentityid'], keep=False)]\n",
    "\n",
    "# Ordenar por 'businessentityid' para facilitar a análise\n",
    "duplicados_ordenados = duplicados_businessentityid.sort_values(by=['businessentityid'])\n",
    "\n",
    "# Exibir todas as linhas duplicadas\n",
    "print(duplicados_ordenados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "contagem = raw_data['businessentityid'].value_counts()\n",
    "\n",
    "# Filtrar apenas os IDs que aparecem mais de uma vez\n",
    "repetidos = contagem[contagem > 1]\n",
    "\n",
    "# Exibir repetidos novamente\n",
    "print(repetidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copia da humanresources_employee\n",
    "raw_data_bkp = raw_data.copy()\n",
    "\n",
    "# Ordenar o DataFrame por 'businessentityid' e 'modifieddate'\n",
    "raw_data = raw_data.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "# Remover duplicatas mantendo a última ocorrência com base em 'modifieddate'\n",
    "raw_data = raw_data.drop_duplicates(subset=['businessentityid'], keep='last')\n",
    "\n",
    "print(f\"Linhas após remover duplicatas (baseando-se na última 'modifieddate'): {len(raw_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar informações do DataFrame\n",
    "print(raw_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas com datas\n",
    "date_columns = ['birthdate', 'hiredate', 'modifieddate']\n",
    "\n",
    "# Converter as colunas para datetime se ainda não estiverem\n",
    "for col in date_columns:\n",
    "    raw_data[col] = pd.to_datetime(raw_data[col], errors='coerce')\n",
    "\n",
    "# Criar uma cópia do DataFrame para exibição formatada\n",
    "formatted_data = raw_data.copy()\n",
    "\n",
    "# Formatar todas as colunas de datas para exibição\n",
    "for col in date_columns:\n",
    "    formatted_data[col] = raw_data[col].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Exibir o DataFrame formatado\n",
    "print(formatted_data.head())\n",
    "\n",
    "# Verificar os tipos originais permanecem datetime64[ns]\n",
    "print(\"\\nTipos originais das colunas no DataFrame principal:\")\n",
    "print(raw_data[date_columns].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar textos em jobtitle e gender\n",
    "raw_data['jobtitle'] = raw_data['jobtitle'].str.strip().str.title()\n",
    "raw_data['gender'] = raw_data['gender'].str.strip().str.upper()\n",
    "\n",
    "# Verificar valores únicos para garantir a padronização\n",
    "print(\"Valores únicos em 'jobtitle':\", raw_data['jobtitle'].unique())\n",
    "print(\"Valores únicos em 'gender':\", raw_data['gender'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas numéricas para análise \n",
    "numeric_columns = ['sickleavehours', 'vacationhours']\n",
    "\n",
    "# Exibir estatísticas descritivas\n",
    "print(raw_data[numeric_columns].describe())\n",
    "\n",
    "# Calcular limites para outliers (IQR - Intervalo Interquartil)\n",
    "for col in numeric_columns:\n",
    "    q1 = raw_data[col].quantile(0.25)\n",
    "    q3 = raw_data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Exibir os limites\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Limite inferior: {lower_bound}, Limite superior: {upper_bound}\")\n",
    "    \n",
    "    # Filtrar outliers\n",
    "    outliers = raw_data[(raw_data[col] < lower_bound) | (raw_data[col] > upper_bound)]\n",
    "    print(f\"Outliers detectados ({len(outliers)}):\")\n",
    "    print(outliers[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar a coluna 'hire_year' com base em 'hiredate'\n",
    "raw_data['hire_year'] = raw_data['hiredate'].dt.year\n",
    "\n",
    "\n",
    "#verificando outros dados para detectar outliers\n",
    "anos_contratacao = [int(ano) for ano in raw_data['hire_year'].unique()]\n",
    "anos_contratacao.sort()\n",
    "print(anos_contratacao)\n",
    "\n",
    "print(\"Valores únicos em 'gender':\", raw_data['gender'].unique())\n",
    "print(\"Valores únicos em 'salariedflag':\", raw_data['salariedflag'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "missing = raw_data.isnull().sum()\n",
    "print(\"Valores ausentes por coluna:\")\n",
    "print(missing)\n",
    "\n",
    "# Tratar colunas críticas\n",
    "if missing['hiredate'] > 0:\n",
    "    print(\"Tratar valores ausentes em 'hiredate' (decisão: remover ou imputar)\")\n",
    "\n",
    "if missing['jobtitle'] > 0:\n",
    "    print(\"Tratar valores ausentes em 'jobtitle' (decisão: remover ou imputar)\")\n",
    "\n",
    "if missing['businessentityid'] > 0:\n",
    "    print(\"Erro crítico: 'businessentityid' não pode ter valores ausentes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar linhas com 'modifieddate' ausente\n",
    "missing_modifieddate = raw_data[raw_data['modifieddate'].isnull()]\n",
    "print(\"Linhas com 'modifieddate' ausente:\")\n",
    "print(missing_modifieddate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher 'modifieddate' ausente ou igual a 'hiredate', pois pode ser a ultima data de modificação no sistema.\n",
    "raw_data.loc[raw_data['modifieddate'].isnull() | (raw_data['modifieddate'] == pd.Timestamp('1900-01-01')), 'modifieddate'] = raw_data['hiredate']\n",
    "\n",
    "# Exibir as linhas ajustadas\n",
    "print(\"Linhas onde 'modifieddate' foi ajustado para 'hiredate':\")\n",
    "print(raw_data.loc[raw_data['modifieddate'] == raw_data['hiredate']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar unicidade de 'businessentityid'\n",
    "is_unique = raw_data['businessentityid'].is_unique\n",
    "print(f\"'businessentityid' é único? {is_unique}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir regex para validar números (exemplo: apenas dígitos, 9 caracteres)\n",
    "regex = r'^\\d{9}$'\n",
    "\n",
    "# Verificar valores inválidos\n",
    "invalid_nationalid = raw_data[~raw_data['nationalidnumber'].astype(str).str.match(regex)]\n",
    "print(f\"Valores inválidos em 'nationalidnumber':\\n{invalid_nationalid['nationalidnumber']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_email = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "invalid_loginid = raw_data[~raw_data['loginid'].str.match(regex_email)]\n",
    "print(f\"Valores inválidos em 'loginid':\\n{invalid_loginid['loginid']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_unique = raw_data['nationalidnumber'].is_unique\n",
    "print(f\"'nationalidnumber' é único? {is_unique}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um backup do DataFrame tratado\n",
    "raw_data_bkp_v2 = raw_data.copy()\n",
    "\n",
    "# Verificar o tamanho do backup e as primeiras linhas\n",
    "print(f\"Backup criado com {len(raw_data_bkp_v2)} linhas.\")\n",
    "print(raw_data_bkp_v2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar e documentar colunas existentes\n",
    "print(\"Colunas mantidas no dataset:\", raw_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in raw_data.columns:\n",
    "    print(f\"Valores únicos em '{col}':\", raw_data[col].unique()[:10])  # Limitar a exibição a 10 valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar colunas binárias esperadas\n",
    "binary_columns = ['currentflag', 'salariedflag']\n",
    "\n",
    "# Verificar valores únicos em colunas binárias\n",
    "for col in binary_columns:\n",
    "    unique_values = raw_data[col].unique()\n",
    "    print(f\"Valores únicos em '{col}': {unique_values}\")\n",
    "\n",
    "    # Corrigir valores não binários, se necessário\n",
    "    if not set(unique_values).issubset({True, False, 0, 1}):\n",
    "        pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar valores em 'currentflag' e 'salariedflag'\n",
    "print(\"Distribuição de 'currentflag':\")\n",
    "print(raw_data['currentflag'].value_counts())\n",
    "\n",
    "print(\"\\nDistribuição de 'salariedflag':\")\n",
    "print(raw_data['salariedflag'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verificar se todos os funcionários ativos têm currentflag = True, pois deveria ser false = demitido/desligado\n",
    "print(\"Funcionários ativos errados:\", raw_data[raw_data['currentflag'] != True])\n",
    "\n",
    "# 2. Validar datas\n",
    "print(\"Contratações futuras:\", raw_data[raw_data['hiredate'] > pd.Timestamp.now()])\n",
    "print(\"Modifieddate antes de hiredate:\", raw_data[raw_data['modifieddate'] < raw_data['hiredate']])\n",
    "\n",
    "# 3. Verificar unicidade de identificadores\n",
    "print(\"Duplicados em 'businessentityid':\", raw_data['businessentityid'].duplicated().sum())\n",
    "print(\"Duplicados em 'nationalidnumber':\", raw_data['nationalidnumber'].duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESTATÍSTICA DESCRITIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas relevantes para análise descritiva\n",
    "cols_para_analise = ['sickleavehours', 'vacationhours', 'salariedflag']\n",
    "\n",
    "# Garantir que as datas estejam no formato correto\n",
    "raw_data['hire_year'] = pd.to_datetime(raw_data['hiredate']).dt.year\n",
    "\n",
    "# Adicionar a nova coluna à lista\n",
    "cols_para_analise.append('hire_year')\n",
    "\n",
    "# Gerar estatísticas descritivas\n",
    "analise_descritiva = raw_data[cols_para_analise].describe(include='all')\n",
    "\n",
    "# Substituir NaN por '-'\n",
    "analise_descritiva = analise_descritiva.fillna('-')\n",
    "\n",
    "print(analise_descritiva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
