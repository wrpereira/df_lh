{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Exploratory Data Analysis) & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "credentials_path = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "input_table = \"desafioadventureworks-446600.raw_data.humanresources_employee\"\n",
    "output_table = \"desafioadventureworks-446600.raw_data_cleaned.humanresources_employee\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credenciais do BigQuery: /mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\n",
      "/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##import das bibliotecas e adequando colunas, linhas e formato de números\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Carrega o .env\n",
    "load_dotenv()\n",
    "\n",
    "# Detectar ambiente\n",
    "if os.name == \"nt\":  # Windows\n",
    "    credentials_path = r\"C:\\Temp\\desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "else:  # WSL/Linux\n",
    "    credentials_path = \"/mnt/c/Temp/desafiolh-445818-3cb0f62cb9ef.json\"\n",
    "\n",
    "\n",
    "# Parâmetros injetados pelo Papermill ou definidos manualmente\n",
    "if 'tables_to_process' not in locals():\n",
    "    tables_to_process = [\n",
    "        \"desafioadventureworks-446600.raw_data.humanresources_employee\"       \n",
    "    ]\n",
    "\n",
    "if 'output_dataset' not in locals():\n",
    "    output_dataset = \"desafioadventureworks-446600.raw_data_cleaned\"\n",
    "\n",
    "\n",
    "# Configurar o cliente do BigQuery com project e location dinâmicos\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials, project=os.getenv(\"BIGQUERY_PROJECT\"), location=\"us-central1\")\n",
    "\n",
    "\n",
    "# Verificar se a configuração está correta\n",
    "print(\"Credenciais do BigQuery:\", os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "\n",
    "# Verifica se a variável está configurada\n",
    "print(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas a processar: ['desafioadventureworks-446600.raw_data.humanresources_employee']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabelas a processar:\", tables_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials, project=\"desafioadventureworks-446600\", location=\"us-central1\")\n",
    "\n",
    "\n",
    "# # Configurar o cliente do BigQuery\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# Nome do dataset e tabela\n",
    "dataset_id = 'raw_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Pandas para exibir todas as colunas e todas as linhas completas\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas disponíveis:\n",
      "humanresources_employee\n"
     ]
    }
   ],
   "source": [
    "# Listar tabelas no dataset\n",
    "tables = client.list_tables('raw_data')\n",
    "print(\"Tabelas disponíveis:\")\n",
    "for table in tables:\n",
    "    print(table.table_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando tabela: desafioadventureworks-446600.raw_data.humanresources_employee\n",
      "Lendo os dados do BigQuery...\n",
      "Transformando os dados para formato tabular...\n",
      "Tabela humanresources_employee processada e armazenada com sucesso.\n",
      "Todas as tabelas foram processadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o cliente do BigQuery\n",
    "client = bigquery.Client(credentials=credentials, project=\"desafioadventureworks-446600\", location=\"us-central1\")\n",
    "\n",
    "# Configurar o cliente do BigQuery com project e location dinâmicos\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "\n",
    "# Inicializar o cliente do BigQuery Storage\n",
    "bqstorage_client = BigQueryReadClient(credentials=credentials)\n",
    "\n",
    "\n",
    "# Dicionário para armazenar DataFrames processados\n",
    "processed_data = {}\n",
    "\n",
    "# Processar tabelas e armazenar DataFrames\n",
    "for input_table in tables_to_process:\n",
    "    print(f\"Processando tabela: {input_table}\")\n",
    "    \n",
    "    # Nome da tabela\n",
    "    table_name = input_table.split(\".\")[-1]  # Extrai o nome da tabela\n",
    "    \n",
    "    # Etapa 1: Ler os dados da tabela do BigQuery com pyarrow\n",
    "    print(\"Lendo os dados do BigQuery...\")\n",
    "    query = f\"SELECT * FROM `{input_table}`\"\n",
    "    EDA_humanresources_employee_raw = client.query(query).to_dataframe(bqstorage_client=bqstorage_client)\n",
    "\n",
    "    # Etapa 2: Transformar JSON em formato tabular\n",
    "    print(\"Transformando os dados para formato tabular...\")\n",
    "\n",
    "    # Verificar se há colunas com dados em formato JSON\n",
    "    if EDA_humanresources_employee_raw.shape[1] == 1 and isinstance(EDA_humanresources_employee_raw.iloc[0, 0], str):\n",
    "        try:\n",
    "            print(\"Normalizando dados JSON...\")\n",
    "            # Substituir `null` por `None` e carregar o JSON\n",
    "            EDA_humanresources_employee = pd.json_normalize(\n",
    "                EDA_humanresources_employee_raw.iloc[:, 0].apply(lambda x: json.loads(x.replace(\"null\", \"None\")))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao normalizar JSON: {e}\")\n",
    "            EDA_humanresources_employee = EDA_humanresources_employee  # Caso falhe, mantém os dados brutos\n",
    "    else:\n",
    "        EDA_humanresources_employee = EDA_humanresources_employee_raw\n",
    "\n",
    "    # Armazenar o DataFrame limpo em um dicionário\n",
    "    processed_data[table_name] = EDA_humanresources_employee\n",
    "    print(f\"Tabela {table_name} processada e armazenada com sucesso.\")\n",
    "\n",
    "# Após o loop, exibir uma mensagem de conclusão\n",
    "print(\"Todas as tabelas foram processadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             {\"birthdate\":\"1969-01-29\",\"businessentityid\":1,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2009-01-14\",\"jobtitle\":\"Chief Executive Officer\",\"loginid\":\"adventure-works\\\\ken0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"295847284\",\"organizationnode\":\"/\",\"rowguid\":\"f01251e5-96a3-448d-981e-0f99d789110d\",\"salariedflag\":true,\"sickleavehours\":69,\"vacationhours\":99}\n",
      "1    {\"birthdate\":\"1971-08-01\",\"businessentityid\":2,\"currentflag\":true,\"gender\":\"F\",\"hiredate\":\"2008-01-31\",\"jobtitle\":\"Vice President of Engineering\",\"loginid\":\"adventure-works\\\\terri0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"245797967\",\"organizationnode\":\"/1/\",\"rowguid\":\"45e8f437-670d-4409-93cb-f9424a40d6ee\",\"salariedflag\":true,\"sickleavehours\":20,\"vacationhours\":1}\n",
      "2          {\"birthdate\":\"1974-11-12\",\"businessentityid\":3,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2007-11-11\",\"jobtitle\":\"Engineering Manager\",\"loginid\":\"adventure-works\\\\roberto0\",\"maritalstatus\":\"M\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"509647174\",\"organizationnode\":\"/1/1/\",\"rowguid\":\"9bbbfb2c-efbb-4217-9ab7-f97689328841\",\"salariedflag\":true,\"sickleavehours\":21,\"vacationhours\":2}\n",
      "3         {\"birthdate\":\"1974-12-23\",\"businessentityid\":4,\"currentflag\":true,\"gender\":\"M\",\"hiredate\":\"2007-12-05\",\"jobtitle\":\"Senior Tool Designer\",\"loginid\":\"adventure-works\\\\rob0\",\"maritalstatus\":\"S\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"112457891\",\"organizationnode\":\"/1/1/1/\",\"rowguid\":\"59747955-87b8-443f-8ed4-f8ad3afdf3a9\",\"salariedflag\":false,\"sickleavehours\":80,\"vacationhours\":48}\n",
      "4               {\"birthdate\":\"1952-09-27\",\"businessentityid\":5,\"currentflag\":true,\"gender\":\"F\",\"hiredate\":\"2008-01-06\",\"jobtitle\":\"Design Engineer\",\"loginid\":\"adventure-works\\\\gail0\",\"maritalstatus\":\"M\",\"modifieddate\":\"2014-06-30T00:00:00\",\"nationalidnumber\":\"695256908\",\"organizationnode\":\"/1/1/2/\",\"rowguid\":\"ec84ae09-f9b8-4a15-b4a9-6ccbab919b08\",\"salariedflag\":true,\"sickleavehours\":22,\"vacationhours\":5}\n",
      "Name: data, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(EDA_humanresources_employee_raw.iloc[:, 0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando os dados JSON...\n",
      "Dados normalizados com sucesso!\n",
      "Tipos atribuídos com sucesso!\n",
      "Tabela processada: desafioadventureworks-446600.raw_data.humanresources_employee\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   birthdate         290 non-null    datetime64[ns]\n",
      " 1   businessentityid  290 non-null    int64         \n",
      " 2   currentflag       290 non-null    bool          \n",
      " 3   gender            290 non-null    object        \n",
      " 4   hiredate          290 non-null    datetime64[ns]\n",
      " 5   jobtitle          290 non-null    object        \n",
      " 6   loginid           290 non-null    object        \n",
      " 7   maritalstatus     290 non-null    object        \n",
      " 8   modifieddate      287 non-null    datetime64[ns]\n",
      " 9   nationalidnumber  290 non-null    int64         \n",
      " 10  organizationnode  290 non-null    object        \n",
      " 11  rowguid           290 non-null    object        \n",
      " 12  salariedflag      290 non-null    bool          \n",
      " 13  sickleavehours    290 non-null    int64         \n",
      " 14  vacationhours     290 non-null    int64         \n",
      "dtypes: bool(2), datetime64[ns](3), int64(4), object(6)\n",
      "memory usage: 30.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# def clean_and_load_json(value):\n",
    "#     \"\"\"Função para corrigir e carregar JSON.\"\"\"\n",
    "#     try:\n",
    "#         # Substituir `null` por `None` e carregar o JSON\n",
    "#         value = value.replace(\"null\", \"null\")\n",
    "#         return json.loads(value)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro ao processar JSON: {e}, valor problemático: {value}\")\n",
    "#         return None  # Retorna None se o valor for inválido\n",
    "\n",
    "# # Normalizar os dados JSON\n",
    "# print(\"Normalizando os dados JSON...\")\n",
    "# try:\n",
    "#     EDA_humanresources_employee = pd.json_normalize(\n",
    "#         EDA_humanresources_employee_raw.iloc[:, 0].apply(clean_and_load_json)\n",
    "#     )\n",
    "#     print(\"Dados normalizados com sucesso!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Erro ao normalizar os dados JSON: {e}\")\n",
    "#     EDA_humanresources_employee = EDA_humanresources_employee_raw  # Mantém os dados originais em caso de erro\n",
    "\n",
    "# print(f\"Tabela processada: {input_table}\")\n",
    "# print(EDA_humanresources_employee.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_and_load_json(value):\n",
    "    \"\"\"Função para corrigir e carregar JSON.\"\"\"\n",
    "    try:\n",
    "        # Substituir `null` por `None` e carregar o JSON\n",
    "        value = value.replace(\"null\", \"None\")\n",
    "        return json.loads(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar JSON: {e}, valor problemático: {value}\")\n",
    "        return None  # Retorna None se o valor for inválido\n",
    "\n",
    "# Normalizar os dados JSON\n",
    "print(\"Normalizando os dados JSON...\")\n",
    "try:\n",
    "    EDA_humanresources_employee = pd.json_normalize(\n",
    "        EDA_humanresources_employee_raw.iloc[:, 0].apply(clean_and_load_json)\n",
    "    )\n",
    "    print(\"Dados normalizados com sucesso!\")\n",
    "\n",
    "    # Atribuir tipos às colunas\n",
    "    EDA_humanresources_employee['businessentityid'] = EDA_humanresources_employee['businessentityid'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['nationalidnumber'] = EDA_humanresources_employee['nationalidnumber'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['loginid'] = EDA_humanresources_employee['loginid'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['jobtitle'] = EDA_humanresources_employee['jobtitle'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['birthdate'] = pd.to_datetime(EDA_humanresources_employee['birthdate'], errors='coerce')\n",
    "    EDA_humanresources_employee['maritalstatus'] = EDA_humanresources_employee['maritalstatus'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['gender'] = EDA_humanresources_employee['gender'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['hiredate'] = pd.to_datetime(EDA_humanresources_employee['hiredate'], errors='coerce')\n",
    "    EDA_humanresources_employee['salariedflag'] = EDA_humanresources_employee['salariedflag'].astype('bool')\n",
    "    EDA_humanresources_employee['vacationhours'] = EDA_humanresources_employee['vacationhours'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['sickleavehours'] = EDA_humanresources_employee['sickleavehours'].astype('int64', errors='ignore')\n",
    "    EDA_humanresources_employee['currentflag'] = EDA_humanresources_employee['currentflag'].astype('bool')\n",
    "    EDA_humanresources_employee['rowguid'] = EDA_humanresources_employee['rowguid'].astype('str', errors='ignore')\n",
    "    EDA_humanresources_employee['modifieddate'] = pd.to_datetime(EDA_humanresources_employee['modifieddate'], errors='coerce')\n",
    "    EDA_humanresources_employee['organizationnode'] = EDA_humanresources_employee['organizationnode'].astype('str', errors='ignore')\n",
    "\n",
    "    print(\"Tipos atribuídos com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao normalizar os dados JSON: {e}\")\n",
    "    EDA_humanresources_employee = EDA_humanresources_employee_raw  # Mantém os dados originais em caso de erro\n",
    "\n",
    "print(f\"Tabela processada: {input_table}\")\n",
    "\n",
    "print(EDA_humanresources_employee.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensões do df antes de remover duplicatas\n",
    "\n",
    "EDA_humanresources_employee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis no DataFrame limpo (cleaned): Index(['birthdate', 'businessentityid', 'currentflag', 'gender', 'hiredate', 'jobtitle', 'loginid', 'maritalstatus', 'modifieddate', 'nationalidnumber', 'organizationnode', 'rowguid', 'salariedflag', 'sickleavehours', 'vacationhours'], dtype='object')\n",
      "Não foram encontradas duplicatas.\n"
     ]
    }
   ],
   "source": [
    "print(\"Colunas disponíveis no DataFrame limpo (cleaned):\", EDA_humanresources_employee.columns)\n",
    "\n",
    "# Identificar duplicatas com base em 'businessentityid'\n",
    "duplicatas = EDA_humanresources_employee[\n",
    "    EDA_humanresources_employee.duplicated(subset=['businessentityid'], keep=False)\n",
    "]\n",
    "\n",
    "# Verificar se existem duplicatas\n",
    "if not duplicatas.empty:\n",
    "    # Ordenar duplicatas por 'businessentityid' e 'modifieddate'\n",
    "    duplicatas_ordenadas = duplicatas.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "    # Exibir duplicatas ordenadas\n",
    "    print(\"Duplicatas ordenadas:\")\n",
    "    print(duplicatas_ordenadas)\n",
    "else:\n",
    "    print(\"Não foram encontradas duplicatas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas após remover duplicatas (baseando-se na última 'modifieddate'): 290\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas mantendo a última ocorrência com base em 'modifieddate'\n",
    "EDA_humanresources_employee = EDA_humanresources_employee.drop_duplicates(subset=['businessentityid'], keep='last')\n",
    "\n",
    "print(f\"Linhas após remover duplicatas (baseando-se na última 'modifieddate'): {len(EDA_humanresources_employee)}\")\n",
    "\n",
    "#cópia dados brutos\n",
    "raw_data_bkp_2_sem_duplicatas = EDA_humanresources_employee.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     birthdate  businessentityid  currentflag gender   hiredate                       jobtitle                   loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "0   1969-01-29                 1         True      M 2009-01-14        Chief Executive Officer      adventure-works\\ken0             S   2014-06-30         295847284                /  f01251e5-96a3-448d-981e-0f99d789110d          True              69             99\n",
      "1   1971-08-01                 2         True      F 2008-01-31  Vice President of Engineering    adventure-works\\terri0             S   2014-06-30         245797967              /1/  45e8f437-670d-4409-93cb-f9424a40d6ee          True              20              1\n",
      "2   1974-11-12                 3         True      M 2007-11-11            Engineering Manager  adventure-works\\roberto0             M   2014-06-30         509647174            /1/1/  9bbbfb2c-efbb-4217-9ab7-f97689328841          True              21              2\n",
      "3   1974-12-23                 4         True      M 2007-12-05           Senior Tool Designer      adventure-works\\rob0             S   2014-06-30         112457891          /1/1/1/  59747955-87b8-443f-8ed4-f8ad3afdf3a9         False              80             48\n",
      "4   1952-09-27                 5         True      F 2008-01-06                Design Engineer     adventure-works\\gail0             M   2014-06-30         695256908          /1/1/2/  ec84ae09-f9b8-4a15-b4a9-6ccbab919b08          True              22              5\n",
      "..         ...               ...          ...    ...        ...                            ...                       ...           ...          ...               ...              ...                                   ...           ...             ...            ...\n",
      "285 1977-02-14               286         True      F 2013-05-30           Sales Representative     adventure-works\\lynn0             S   2014-06-30         758596752          /6/2/1/  4a9a8407-a680-4a6b-8d03-511cb58f9a8a          True              38             36\n",
      "286 1957-09-20               287         True      F 2012-04-16         European Sales Manager      adventure-works\\amy0             M   2014-06-30         982310417            /6/3/  66d66445-ee78-4676-9e66-0e22d6109a92          True              30             21\n",
      "287 1975-07-09               288         True      F 2013-05-30           Sales Representative   adventure-works\\rachel0             S   2014-06-30         954276278          /6/3/1/  b9bf7741-e0ca-4f37-acde-a4f78c6d03e9          True              37             35\n",
      "288 1968-03-17               289         True      F 2012-05-30           Sales Representative      adventure-works\\jae0             M   2014-06-30         668991357          /6/3/2/  723a5921-d8a1-4659-9bc4-13c4cf7c9c91          True              38             37\n",
      "289 1975-09-30               290         True      M 2012-05-30           Sales Representative   adventure-works\\ranjit0             S   2014-06-30         134219713          /6/3/3/  604213f9-dd0f-43b4-bdd2-c96e93d3f4bf          True              37             34\n",
      "\n",
      "[290 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ordenar o DataFrame por 'businessentityid' e 'modifieddate'\n",
    "EDA_humanresources_employee = EDA_humanresources_employee.sort_values(by=['businessentityid', 'modifieddate'])\n",
    "\n",
    "print(EDA_humanresources_employee)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   birthdate         290 non-null    datetime64[ns]\n",
      " 1   businessentityid  290 non-null    int64         \n",
      " 2   currentflag       290 non-null    bool          \n",
      " 3   gender            290 non-null    object        \n",
      " 4   hiredate          290 non-null    datetime64[ns]\n",
      " 5   jobtitle          290 non-null    object        \n",
      " 6   loginid           290 non-null    object        \n",
      " 7   maritalstatus     290 non-null    object        \n",
      " 8   modifieddate      287 non-null    datetime64[ns]\n",
      " 9   nationalidnumber  290 non-null    int64         \n",
      " 10  organizationnode  290 non-null    object        \n",
      " 11  rowguid           290 non-null    object        \n",
      " 12  salariedflag      290 non-null    bool          \n",
      " 13  sickleavehours    290 non-null    int64         \n",
      " 14  vacationhours     290 non-null    int64         \n",
      "dtypes: bool(2), datetime64[ns](3), int64(4), object(6)\n",
      "memory usage: 30.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Certifique-se de que as colunas de datas está sendo reconhecida corretamente como contendo valores nulos (NaN em pandas). (Não pode object)\n",
    "\n",
    "print(EDA_humanresources_employee.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   birthdate         290 non-null    datetime64[ns]\n",
      " 1   businessentityid  290 non-null    int64         \n",
      " 2   currentflag       290 non-null    bool          \n",
      " 3   gender            290 non-null    object        \n",
      " 4   hiredate          290 non-null    datetime64[ns]\n",
      " 5   jobtitle          290 non-null    object        \n",
      " 6   loginid           290 non-null    object        \n",
      " 7   maritalstatus     290 non-null    object        \n",
      " 8   modifieddate      287 non-null    datetime64[ns]\n",
      " 9   nationalidnumber  290 non-null    int64         \n",
      " 10  organizationnode  290 non-null    object        \n",
      " 11  rowguid           290 non-null    object        \n",
      " 12  salariedflag      290 non-null    bool          \n",
      " 13  sickleavehours    290 non-null    int64         \n",
      " 14  vacationhours     290 non-null    int64         \n",
      "dtypes: bool(2), datetime64[ns](3), int64(4), object(6)\n",
      "memory usage: 30.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Identificar as colunas de data\n",
    "date_columns = ['birthdate', 'hiredate', 'modifieddate']\n",
    "\n",
    "# Converter todas as colunas para datetime\n",
    "for col in date_columns:\n",
    "    EDA_humanresources_employee[col] = pd.to_datetime(\n",
    "        EDA_humanresources_employee[col], errors='coerce'\n",
    "    )\n",
    "\n",
    "# Criar uma cópia do DataFrame para exportação no formato JSON\n",
    "datas_formatadas = EDA_humanresources_employee.copy()\n",
    "\n",
    "# Formatar colunas no formato ISO 8601 para BigQuery e tratar nulos como null\n",
    "for col in date_columns:\n",
    "    datas_formatadas[col] = datas_formatadas[col].apply(\n",
    "        lambda x: x.isoformat() if pd.notnull(x) else None  # Certifique-se de que é datetime\n",
    "    )\n",
    "\n",
    "print(EDA_humanresources_employee.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna 'birthdate': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'birthdate'.\n",
      "\n",
      "Coluna 'businessentityid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'businessentityid'.\n",
      "\n",
      "Coluna 'currentflag': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'currentflag'.\n",
      "\n",
      "Coluna 'gender': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'gender'.\n",
      "\n",
      "Coluna 'hiredate': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'hiredate'.\n",
      "\n",
      "Coluna 'jobtitle': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'jobtitle'.\n",
      "\n",
      "Coluna 'loginid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'loginid'.\n",
      "\n",
      "Coluna 'maritalstatus': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'maritalstatus'.\n",
      "\n",
      "Coluna 'modifieddate': 3 linhas ausentes.\n",
      "Exibindo as primeiras linhas com valores ausentes em 'modifieddate':\n",
      "     birthdate  businessentityid  currentflag gender   hiredate                    jobtitle                  loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "25  1982-11-03                26         True      M 2008-12-01  Production Control Manager   adventure-works\\peter0             M          NaT         277173473            /3/1/  69d5d162-e817-45e7-9dec-5d9b8310e7b1          True              41             43\n",
      "210 1977-10-26               211         True      M 2009-02-28   Quality Assurance Manager   adventure-works\\hazem0             S          NaT         398223854            /3/2/  05c84608-f445-4f9d-bb5c-0828c309c29d          True              60             80\n",
      "221 1968-09-17               222         True      M 2008-12-12            Master Scheduler  adventure-works\\ascott0             S          NaT         685233686            /3/3/  13909262-4136-492f-bca3-0b0e3773b03e         False              42             44 \n",
      "\n",
      "Coluna 'nationalidnumber': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'nationalidnumber'.\n",
      "\n",
      "Coluna 'organizationnode': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'organizationnode'.\n",
      "\n",
      "Coluna 'rowguid': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'rowguid'.\n",
      "\n",
      "Coluna 'salariedflag': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'salariedflag'.\n",
      "\n",
      "Coluna 'sickleavehours': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'sickleavehours'.\n",
      "\n",
      "Coluna 'vacationhours': 0 linhas ausentes.\n",
      "Nenhuma linha com valores ausentes em 'vacationhours'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar por todas as colunas do DataFrame\n",
    "\n",
    "for column in EDA_humanresources_employee.columns:\n",
    "    # Verificar valores ausentes na coluna\n",
    "    missing_rows = EDA_humanresources_employee[EDA_humanresources_employee[column].isnull()]\n",
    "    print(f\"Coluna '{column}': {missing_rows.shape[0]} linhas ausentes.\")\n",
    "    \n",
    "    # Mostrar as primeiras linhas ausentes (limitar para não poluir a saída)\n",
    "    if not missing_rows.empty:\n",
    "        print(f\"Exibindo as primeiras linhas com valores ausentes em '{column}':\")\n",
    "        print(missing_rows.head(), \"\\n\")\n",
    "    else:\n",
    "        print(f\"Nenhuma linha com valores ausentes em '{column}'.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas onde 'modifieddate' foi ajustado para 'hiredate':\n",
      "     birthdate  businessentityid  currentflag gender   hiredate                    jobtitle                  loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "25  1982-11-03                26         True      M 2008-12-01  Production Control Manager   adventure-works\\peter0             M   2008-12-01         277173473            /3/1/  69d5d162-e817-45e7-9dec-5d9b8310e7b1          True              41             43\n",
      "210 1977-10-26               211         True      M 2009-02-28   Quality Assurance Manager   adventure-works\\hazem0             S   2009-02-28         398223854            /3/2/  05c84608-f445-4f9d-bb5c-0828c309c29d          True              60             80\n",
      "221 1968-09-17               222         True      M 2008-12-12            Master Scheduler  adventure-works\\ascott0             S   2008-12-12         685233686            /3/3/  13909262-4136-492f-bca3-0b0e3773b03e         False              42             44\n"
     ]
    }
   ],
   "source": [
    "# Preencher 'modifieddate' ausente ou igual a 'hiredate', pois pode ser a ultima data de modificação no sistema.\n",
    "EDA_humanresources_employee.loc[EDA_humanresources_employee['modifieddate'].isnull() | (EDA_humanresources_employee['modifieddate'] == pd.Timestamp('1900-01-01')), 'modifieddate'] = EDA_humanresources_employee['hiredate']\n",
    "\n",
    "# Exibir as linhas ajustadas\n",
    "print(\"Linhas onde 'modifieddate' foi ajustado para 'hiredate':\")\n",
    "print(EDA_humanresources_employee.loc[EDA_humanresources_employee['modifieddate'] == EDA_humanresources_employee['hiredate']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma cópia do DataFrame para exportação no formato JSON\n",
    "ajustes_date_time = EDA_humanresources_employee.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos incluindo NaN:\n",
      "birthdate           275\n",
      "businessentityid    290\n",
      "currentflag           1\n",
      "gender                2\n",
      "hiredate            164\n",
      "jobtitle             67\n",
      "loginid             290\n",
      "maritalstatus         2\n",
      "modifieddate          4\n",
      "nationalidnumber    290\n",
      "organizationnode    290\n",
      "rowguid             290\n",
      "salariedflag          2\n",
      "sickleavehours       51\n",
      "vacationhours       100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# valores únicos por coluna\n",
    "\n",
    "valores_unicos = EDA_humanresources_employee.nunique(dropna=False)\n",
    "\n",
    "print(\"Valores únicos incluindo NaN:\")\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropar colunas vazias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'jobtitle': ['Chief Executive Officer' 'Vice President Of Engineering'\n",
      " 'Engineering Manager' 'Senior Tool Designer' 'Design Engineer'\n",
      " 'Research And Development Manager' 'Research And Development Engineer'\n",
      " 'Tool Designer' 'Senior Design Engineer' 'Marketing Manager'\n",
      " 'Marketing Assistant' 'Marketing Specialist'\n",
      " 'Vice President Of Production' 'Production Control Manager'\n",
      " 'Production Supervisor - Wc60' 'Production Technician - Wc60'\n",
      " 'Production Supervisor - Wc10' 'Production Technician - Wc10'\n",
      " 'Production Supervisor - Wc50' 'Production Technician - Wc50'\n",
      " 'Production Supervisor - Wc30' 'Production Technician - Wc30'\n",
      " 'Production Supervisor - Wc40' 'Production Technician - Wc40'\n",
      " 'Shipping And Receiving Supervisor' 'Stocker'\n",
      " 'Shipping And Receiving Clerk' 'Production Supervisor - Wc20'\n",
      " 'Production Technician - Wc20' 'Production Supervisor - Wc45'\n",
      " 'Production Technician - Wc45' 'Quality Assurance Manager'\n",
      " 'Quality Assurance Supervisor' 'Quality Assurance Technician'\n",
      " 'Document Control Manager' 'Control Specialist'\n",
      " 'Document Control Assistant' 'Master Scheduler' 'Scheduling Assistant'\n",
      " 'Facilities Manager' 'Maintenance Supervisor' 'Janitor'\n",
      " 'Facilities Administrative Assistant' 'Chief Financial Officer'\n",
      " 'Human Resources Manager' 'Human Resources Administrative Assistant'\n",
      " 'Recruiter' 'Benefits Specialist' 'Accounts Manager'\n",
      " 'Accounts Receivable Specialist' 'Accountant'\n",
      " 'Accounts Payable Specialist' 'Finance Manager' 'Purchasing Manager'\n",
      " 'Buyer' 'Purchasing Assistant' 'Assistant To The Chief Financial Officer'\n",
      " 'Information Services Manager' 'Network Manager' 'Network Administrator'\n",
      " 'Application Specialist' 'Database Administrator'\n",
      " 'Vice President Of Sales' 'North American Sales Manager'\n",
      " 'Sales Representative' 'Pacific Sales Manager' 'European Sales Manager']\n",
      "Valores únicos em 'gender': ['M' 'F']\n",
      "Valores únicos em 'gender': ['S' 'M']\n"
     ]
    }
   ],
   "source": [
    "# Padronizar textos em title ou upper\n",
    "EDA_humanresources_employee['jobtitle'] = EDA_humanresources_employee['jobtitle'].str.strip().str.title()\n",
    "EDA_humanresources_employee['gender'] = EDA_humanresources_employee['gender'].str.strip().str.upper()\n",
    "EDA_humanresources_employee['maritalstatus'] = EDA_humanresources_employee['maritalstatus'].str.strip().str.upper()\n",
    "\n",
    "\n",
    "# Verificar valores únicos para garantir a padronização\n",
    "print(\"Valores únicos em 'jobtitle':\", EDA_humanresources_employee['jobtitle'].unique())\n",
    "print(\"Valores únicos em 'gender':\", EDA_humanresources_employee['gender'].unique())\n",
    "print(\"Valores únicos em 'gender':\", EDA_humanresources_employee['maritalstatus'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sickleavehours  vacationhours\n",
      "count          290.00         290.00\n",
      "mean            45.31          50.61\n",
      "std             14.54          28.79\n",
      "min             20.00           0.00\n",
      "25%             33.00          26.25\n",
      "50%             46.00          51.00\n",
      "75%             58.00          75.00\n",
      "max             80.00          99.00\n",
      "\n",
      "Coluna: sickleavehours\n",
      "Limite inferior: -4.5, Limite superior: 95.5\n",
      "Outliers detectados (0):\n",
      "Empty DataFrame\n",
      "Columns: [sickleavehours]\n",
      "Index: []\n",
      "\n",
      "Coluna: vacationhours\n",
      "Limite inferior: -46.875, Limite superior: 148.125\n",
      "Outliers detectados (0):\n",
      "Empty DataFrame\n",
      "Columns: [vacationhours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identificar colunas numéricas para análise \n",
    "numeric_columns = ['sickleavehours', 'vacationhours']\n",
    "\n",
    "# Exibir estatísticas descritivas\n",
    "print(EDA_humanresources_employee[numeric_columns].describe())\n",
    "\n",
    "# Calcular limites para outliers (IQR - Intervalo Interquartil)\n",
    "for col in numeric_columns:\n",
    "    q1 = EDA_humanresources_employee[col].quantile(0.25)\n",
    "    q3 = EDA_humanresources_employee[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Exibir os limites\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Limite inferior: {lower_bound}, Limite superior: {upper_bound}\")\n",
    "    \n",
    "    # Filtrar outliers\n",
    "    outliers = EDA_humanresources_employee[(EDA_humanresources_employee[col] < lower_bound) | (EDA_humanresources_employee[col] > upper_bound)]\n",
    "    print(f\"Outliers detectados ({len(outliers)}):\")\n",
    "    print(outliers[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores inválidos em 'nationalidnumber':\n",
      "13     42487730\n",
      "14     56920285\n",
      "15     24756624\n",
      "18     52541318\n",
      "21     95958330\n",
      "23     72636981\n",
      "27     14417807\n",
      "37      6298838\n",
      "45     66073987\n",
      "46     33237992\n",
      "52      9659517\n",
      "56     10708100\n",
      "60     92096924\n",
      "64      8066363\n",
      "66     63179277\n",
      "69     36151748\n",
      "81     58791499\n",
      "84      1662732\n",
      "86      7201901\n",
      "88     90888098\n",
      "89     82638150\n",
      "112    54759846\n",
      "131     1300049\n",
      "133    45615666\n",
      "136    63761469\n",
      "137    25011600\n",
      "142    56772045\n",
      "153    97728960\n",
      "163    65848458\n",
      "165    60114406\n",
      "172    87268837\n",
      "197    19312190\n",
      "209    20244403\n",
      "229    28414965\n",
      "240       30845\n",
      "242    60517918\n",
      "258    20269531\n",
      "266    58317344\n",
      "279    61161660\n",
      "283    90836195\n",
      "Name: nationalidnumber, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Definir regex para validar números (exemplo: apenas dígitos, 9 caracteres)\n",
    "# acrescentei para ver se tinha um padrão, mas não tem\n",
    "regex = r'^\\d{9}$'\n",
    "\n",
    "# Verificar valores inválidos\n",
    "invalid_nationalid = EDA_humanresources_employee[~EDA_humanresources_employee['nationalidnumber'].astype(str).str.match(regex)]\n",
    "print(f\"Valores inválidos em 'nationalidnumber':\\n{invalid_nationalid['nationalidnumber']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup criado com 290 linhas.\n",
      "   birthdate  businessentityid  currentflag gender   hiredate                       jobtitle                   loginid maritalstatus modifieddate  nationalidnumber organizationnode                               rowguid  salariedflag  sickleavehours  vacationhours\n",
      "0 1969-01-29                 1         True      M 2009-01-14        Chief Executive Officer      adventure-works\\ken0             S   2014-06-30         295847284                /  f01251e5-96a3-448d-981e-0f99d789110d          True              69             99\n",
      "1 1971-08-01                 2         True      F 2008-01-31  Vice President Of Engineering    adventure-works\\terri0             S   2014-06-30         245797967              /1/  45e8f437-670d-4409-93cb-f9424a40d6ee          True              20              1\n",
      "2 1974-11-12                 3         True      M 2007-11-11            Engineering Manager  adventure-works\\roberto0             M   2014-06-30         509647174            /1/1/  9bbbfb2c-efbb-4217-9ab7-f97689328841          True              21              2\n",
      "3 1974-12-23                 4         True      M 2007-12-05           Senior Tool Designer      adventure-works\\rob0             S   2014-06-30         112457891          /1/1/1/  59747955-87b8-443f-8ed4-f8ad3afdf3a9         False              80             48\n",
      "4 1952-09-27                 5         True      F 2008-01-06                Design Engineer     adventure-works\\gail0             M   2014-06-30         695256908          /1/1/2/  ec84ae09-f9b8-4a15-b4a9-6ccbab919b08          True              22              5\n"
     ]
    }
   ],
   "source": [
    "# Criar um backup do DataFrame tratado\n",
    "EDA_humanresources_employee_bkp_v2 = EDA_humanresources_employee.copy()\n",
    "\n",
    "# Verificar o tamanho do backup e as primeiras linhas\n",
    "print(f\"Backup criado com {len(EDA_humanresources_employee_bkp_v2)} linhas.\")\n",
    "print(EDA_humanresources_employee_bkp_v2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas mantidas no dataset: ['birthdate', 'businessentityid', 'currentflag', 'gender', 'hiredate', 'jobtitle', 'loginid', 'maritalstatus', 'modifieddate', 'nationalidnumber', 'organizationnode', 'rowguid', 'salariedflag', 'sickleavehours', 'vacationhours']\n"
     ]
    }
   ],
   "source": [
    "# Verificar e documentar colunas existentes\n",
    "print(\"Colunas mantidas no dataset:\", EDA_humanresources_employee.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos em 'currentflag': [ True]\n",
      "Valores únicos em 'salariedflag': [ True False]\n"
     ]
    }
   ],
   "source": [
    "# Listar colunas binárias esperadas\n",
    "binary_columns = ['currentflag', 'salariedflag']\n",
    "\n",
    "# Verificar valores únicos em colunas binárias\n",
    "for col in binary_columns:\n",
    "    unique_values = EDA_humanresources_employee[col].unique()\n",
    "    print(f\"Valores únicos em '{col}': {unique_values}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de 'currentflag':\n",
      "currentflag\n",
      "True    290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição de 'salariedflag':\n",
      "salariedflag\n",
      "False    238\n",
      "True      52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores em 'currentflag' e 'salariedflag'\n",
    "print(\"Distribuição de 'currentflag':\")\n",
    "print(EDA_humanresources_employee['currentflag'].value_counts())\n",
    "\n",
    "print(\"\\nDistribuição de 'salariedflag':\")\n",
    "print(EDA_humanresources_employee['salariedflag'].value_counts())\n",
    "\n",
    "\n",
    "#se vale a pena deletar ou não a coluna currentflag, já que só tem 1 valor e é true ?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcionários ativos errados: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n",
      "Contratações futuras: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n",
      "Modifieddate antes de hiredate: Empty DataFrame\n",
      "Columns: [birthdate, businessentityid, currentflag, gender, hiredate, jobtitle, loginid, maritalstatus, modifieddate, nationalidnumber, organizationnode, rowguid, salariedflag, sickleavehours, vacationhours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 1. Verificar se todos os funcionários ativos têm currentflag = True, pois deveria ser false = demitido/desligado\n",
    "print(\"Funcionários ativos errados:\", EDA_humanresources_employee[EDA_humanresources_employee['currentflag'] != True])\n",
    "\n",
    "# 2. Validar datas\n",
    "print(\"Contratações futuras:\", EDA_humanresources_employee[EDA_humanresources_employee['hiredate'] > pd.Timestamp.now()])\n",
    "print(\"Modifieddate antes de hiredate:\", EDA_humanresources_employee[EDA_humanresources_employee['modifieddate'] < EDA_humanresources_employee['hiredate']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportando tabela humanresources_employee para o BigQuery...\n",
      "Tabela humanresources_employee exportada com sucesso para desafioadventureworks-446600.raw_data_cleaned.humanresources_employee.\n"
     ]
    }
   ],
   "source": [
    "# Ajustar o formato das colunas de data para atender ao BigQuery\n",
    "EDA_humanresources_employee['modifieddate'] = pd.to_datetime(EDA_humanresources_employee['modifieddate'], errors='coerce').dt.date\n",
    "EDA_humanresources_employee['birthdate'] = pd.to_datetime(EDA_humanresources_employee['birthdate'], errors='coerce').dt.date\n",
    "EDA_humanresources_employee['hiredate'] = pd.to_datetime(EDA_humanresources_employee['hiredate'], errors='coerce').dt.date\n",
    "\n",
    "# Atualizar o dicionário processed_data com o DataFrame ajustado\n",
    "processed_data['humanresources_employee'] = EDA_humanresources_employee\n",
    "\n",
    "# Exportar tabelas para o BigQuery no formato CSV\n",
    "for table_name, df_cleaned in processed_data.items():\n",
    "    output_table = f\"{output_dataset}.{table_name}\"\n",
    "    \n",
    "    print(f\"Exportando tabela {table_name} para o BigQuery...\")\n",
    "\n",
    "    # Definir o esquema explicitamente\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"birthdate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"businessentityid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"currentflag\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"gender\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"hiredate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"jobtitle\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"loginid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"maritalstatus\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"modifieddate\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"nationalidnumber\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"organizationnode\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"rowguid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"salariedflag\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"sickleavehours\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"vacationhours\", \"INTEGER\"),\n",
    "    ]\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=0,\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "        schema=schema,  # Especifica os tipos de dados explicitamente\n",
    "    )\n",
    "\n",
    "    # Exportar para o BigQuery\n",
    "    job = client.load_table_from_dataframe(df_cleaned, output_table, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Tabela {table_name} exportada com sucesso para {output_table}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESTATÍSTICA DESCRITIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sickleavehours  vacationhours  hire_year\n",
      "count          290.00         290.00     290.00\n",
      "mean            45.31          50.61    2009.02\n",
      "std             14.54          28.79       1.01\n",
      "min             20.00           0.00    2006.00\n",
      "25%             33.00          26.25    2008.00\n",
      "50%             46.00          51.00    2009.00\n",
      "75%             58.00          75.00    2009.00\n",
      "max             80.00          99.00    2013.00\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas relevantes para análise descritiva\n",
    "cols_para_analise = ['sickleavehours', 'vacationhours']\n",
    "\n",
    "# Garantir que as datas estejam no formato correto\n",
    "EDA_humanresources_employee['hire_year'] = pd.to_datetime(EDA_humanresources_employee['hiredate']).dt.year\n",
    "\n",
    "# Adicionar a nova coluna à lista\n",
    "cols_para_analise.append('hire_year')\n",
    "\n",
    "# Gerar estatísticas descritivas\n",
    "analise_descritiva = EDA_humanresources_employee[cols_para_analise].describe(include='all')\n",
    "\n",
    "# Substituir NaN em colunas numéricas por 0, e em outras colunas por '-'\n",
    "for col in cols_para_analise:\n",
    "    if analise_descritiva[col].dtype.kind in 'ifc':  # Tipos numéricos\n",
    "        analise_descritiva[col] = analise_descritiva[col].fillna(0)\n",
    "    else:\n",
    "        analise_descritiva[col] = analise_descritiva[col].fillna('-')\n",
    "\n",
    "# Gerar estatísticas descritivas\n",
    "resultado_descritivo = analise_descritiva.describe(include='all')\n",
    "\n",
    "print(analise_descritiva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
